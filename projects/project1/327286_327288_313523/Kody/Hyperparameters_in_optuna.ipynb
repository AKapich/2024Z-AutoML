{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FESMflgDNDO4"
   },
   "source": [
    "# Optimizing hyperparameters for ElasticNet, ExtraTrees and XGBoost with Optuna\n",
    "\n",
    "**Zbiory danych**:\n",
    "1. Kredyty: https://www.openml.org/search?type=data&sort=runs&id=31&status=active&fbclid=IwZXh0bgNhZW0CMTEAAR0LEBUzDmkBWU5CJnI93mAsYUDFilVrhmiXRyS_JDMNZmcdzgBLqPhzlh4_aem_6sDeQnXFdTyQdDh1LyZAxQ\n",
    "2.  Cukrzyca: https://www.openml.org/search?type=data&sort=runs&id=37&status=active&fbclid=IwZXh0bgNhZW0CMTEAAR0I4wZuCTTESyFUjUcDwJs35bTnJs7bqnIEmlVZbL-6fxHbKLMW7L_Ly4A_aem_WFz0zwQx3GFdSdlD3UQszg\n",
    "3. Transfuzja krwi: https://www.openml.org/search?type=data&sort=runs&id=1464&status=active&fbclid=IwZXh0bgNhZW0CMTEAAR2sNl5JdGtoyl5fXCGpQXSjATOnHyswHo99zDt9THChDRmqDi2RgKr2Fa8_aem_2wGmFakw-Bj8BUXn4HDt8g\n",
    "4. Wine: https://www.openml.org/search?type=data&sort=qualities.NumberOfFeatures&status=active&qualities.NumberOfClasses=%3D_2&qualities.NumberOfFeatures=between_10_100&order=asc&qualities.NumberOfInstances=between_1000_10000&id=43980\n",
    "\n",
    "**Algorytmy ML:**\n",
    "\n",
    "1. Elastic Net: C, l1_ratio, penalty\n",
    "2. Extra Trees: n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features, criterion\n",
    "3. XGBoost: n_estimators, max_depth, learning_rate, booster, gamma, subsample, reg_alpha, reg_lambda\n",
    "\n",
    "\n",
    "**Metody optymalizacji:**\n",
    "\n",
    "A) Dla wszystkich zbiorów jednocześnie by obliczyć $\\theta^*$\n",
    "- RandomSerach\n",
    "- Ewentualnie: Bayes Search z agregacją na poziomie funkcji objective(trial) w optunie\n",
    "\n",
    "B) Dla każdego ze zbiorów osobno aby policzyć tunowalność algorytmów ML:\n",
    "- RandomSearch\n",
    "- Bayes Search oparty o Gaussian Processes\n",
    "- Tree-structured Parzen Estimator\n",
    "\n",
    "\n",
    "**Funkcje celu:**\n",
    "- AUC\n",
    "- Accuracy\n",
    "- F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T20:24:22.053711Z",
     "start_time": "2024-11-14T20:24:20.677808Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from utils import config as config\n",
    "from utils.save_results import save_study_to_pickle_joint as save_study_to_pickle_joint, save_best_params_to_json_joint\n",
    "from utils.save_results import save_study_to_pickle_marginal as save_study_to_pickle_marginal\n",
    "from utils.save_results import save_best_params_to_json_joint as save_best_params_to_json_joint\n",
    "from utils.save_results import save_best_params_to_json_marginal as save_best_params_to_json_marginal\n",
    "from utils.save_results import read_study_from_pickle_joint as read_study_from_pickle_joint\n",
    "from utils.save_results import read_study_from_pickle_marginal as read_study_from_pickle_marginal\n",
    "from utils.save_results import read_best_params_from_json_joint as read_best_params_from_json_joint\n",
    "from utils.save_results import read_best_params_from_json_marginal as read_best_params_from_json_marginal\n",
    "\n",
    "import utils\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.WARN)\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "SEED = config.RANDOM_SEED\n",
    "SEEDS = config.RANDOM_SEEDS\n",
    "DATASET_IDS = config.DATASET_IDS\n",
    "MODELS = config.MODELS\n",
    "SAMPLERS = config.SAMPLERS\n",
    "SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "preprocessing = utils.preprocessing\n",
    "\n",
    "results_dir = os.path.join(os.getcwd(), 'results')\n",
    "results_studies_dir = os.path.join(results_dir, 'studies')\n",
    "os.makedirs(results_studies_dir, exist_ok=True)\n",
    "results_bestparams_dir = os.path.join(results_dir, 'best_params')\n",
    "os.makedirs(results_bestparams_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T20:24:22.081475Z",
     "start_time": "2024-11-14T20:24:22.063046Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 01:33:54,179 - openml.datasets.dataset - INFO - pickle write credit-g\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 01:33:54,183 - openml.datasets.dataset - DEBUG - Saved dataset 31: credit-g to file /Users/hubert/.openml/org/openml/www/datasets/31/dataset_31.pkl.py3\n",
      "2024-11-15 01:33:54,204 - openml.datasets.dataset - INFO - pickle write diabetes\n",
      "2024-11-15 01:33:54,205 - openml.datasets.dataset - DEBUG - Saved dataset 37: diabetes to file /Users/hubert/.openml/org/openml/www/datasets/37/dataset_37.pkl.py3\n",
      "2024-11-15 01:33:54,213 - openml.datasets.dataset - INFO - pickle write shrutime\n",
      "2024-11-15 01:33:54,216 - openml.datasets.dataset - DEBUG - Saved dataset 45062: shrutime to file /Users/hubert/.openml/org/openml/www/datasets/45062/dataset_45062.pkl.py3\n",
      "2024-11-15 01:33:54,224 - openml.datasets.dataset - INFO - pickle write wine\n",
      "2024-11-15 01:33:54,225 - openml.datasets.dataset - DEBUG - Saved dataset 43980: wine to file /Users/hubert/.openml/org/openml/www/datasets/43980/dataset_43980.pkl.py3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ID=31, shape: (1000, 21), 0 missing values\n",
      "Dataset ID=37, shape: (768, 9), 0 missing values\n",
      "Dataset ID=45062, shape: (10000, 11), 0 missing values\n",
      "Dataset ID=43980, shape: (2554, 12), 0 missing values\n"
     ]
    }
   ],
   "source": [
    "Xs, ys = utils.get_data(DATASET_IDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T20:24:24.795528Z",
     "start_time": "2024-11-14T20:24:22.192660Z"
    }
   },
   "outputs": [],
   "source": [
    "Xs = [pd.DataFrame(preprocessing.fit_transform(X)) for X in Xs]\n",
    "logger.info('Preprocessing done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T20:24:24.817105Z",
     "start_time": "2024-11-14T20:24:24.813670Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment_joint(model_class, sampler_class, Xs, ys, param_space, results_dir, n_trials=10):\n",
    "    \"\"\"\n",
    "    Run the optimization process for all datasets simultaneously, given the model_class and a sampler.\n",
    "    The result of this function (after analyzing the results) is a single set of hyperparameters \n",
    "    that are optimal for all datasets.\n",
    "    \n",
    "    Args:\n",
    "        model_class: class of the model to be optimized\n",
    "        sampler_class: class of the sampler to be used\n",
    "        Xs: list of Xs of the datasets\n",
    "        ys: list of ys of the datasets\n",
    "        param_space: dictionary of hyperparameters and their ranges\n",
    "        results_dir: path to the directory where the results will be saved\n",
    "        n_trials: number of trials for the optimization process\n",
    "        \n",
    "    Dependencies:\n",
    "        run_study: function that runs optuna optimization\n",
    "    \"\"\"\n",
    "    \n",
    "    sampler_name = sampler_class.__name__\n",
    "    model_name = model_class.__name__\n",
    "    \n",
    "    logger.info(f\"Searching hyperparameter space with {sampler_name} for {model_name}\")\n",
    "    path_joint = os.path.join(results_dir, f\"{model_name}_{sampler_name}_joint.csv\")\n",
    "\n",
    "    logger.info(\"Optimizing hyperparameters for all datasets simultaneously to calculate optimal defaults\")\n",
    "    trials, study = run_study(objective, model_class, sampler_class, Xs, ys, param_space, n_trials=n_trials)\n",
    "    trials.to_csv(path_joint)\n",
    "    logger.info(f\"Results saved to {path_joint}\")\n",
    "    \n",
    "    return trials, study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T20:24:24.860229Z",
     "start_time": "2024-11-14T20:24:24.856639Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment_marginal(model_class, sampler_class, X, y, ID, param_space, results_dir, n_trials=10):\n",
    "    \"\"\"\n",
    "    Run the optimization process for a single dataset, given the model_class and a sampler.\n",
    "    \n",
    "    Args:\n",
    "        model_class: class of the model to be optimized\n",
    "        sampler_class: class of the sampler to be used\n",
    "        X: X of the dataset\n",
    "        y: y of the dataset\n",
    "        ID: id of the dataset being used for this particular experiment (id of (X,y))\n",
    "        param_space: dictionary of hyperparameters and their ranges\n",
    "        results_dir: path to the directory where the results will be saved\n",
    "        n_trials: number of trials for the optimization process\n",
    "    \"\"\"\n",
    "    \n",
    "    sampler_name = sampler_class.__name__\n",
    "    model_name = model_class.__name__\n",
    "    \n",
    "    logger.info(f\"Searching hyperparameter space with {sampler_name} for {model_name}\")\n",
    "    path_marginal = os.path.join(results_dir, f\"{model_name}_{sampler_name}_marginal_{ID}.csv\")\n",
    "\n",
    "    logger.info(f\"Optimizing hyperparameters for dataset separately, dataset {ID}\")\n",
    "    trials, study = run_study(objective, model_class, sampler_class, [X], [y], param_space, n_trials=n_trials)\n",
    "    trials['dataset'] = ID\n",
    "\n",
    "    trials.to_csv(path_marginal)\n",
    "    logger.info(f\"Results saved to {path_marginal}\")\n",
    "    \n",
    "    return trials, study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T20:24:24.908229Z",
     "start_time": "2024-11-14T20:24:24.904379Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial, model_class, Xs, ys, param_space):\n",
    "    \"\"\"\n",
    "    The most important function for optimization with optuna. It is invoked in every iteration\n",
    "    of the optimization process when optuna.study.optimize() is called. In mathematical terms,\n",
    "    this is the objective function that the algorithm is trying to optimize (maximize in this case).\n",
    "    \n",
    "    Args:\n",
    "        trial: optuna.trial.Trial\n",
    "        model_class: class of the model to be optimized\n",
    "        Xs: list of Xs of the datasets\n",
    "        ys: list of ys of the datasets\n",
    "        param_space: dictionary of hyperparameters and their ranges\n",
    "        \n",
    "    Dependencies:\n",
    "        utils.sample_parameter: function that samples a value from the range of a hyperparameter,\n",
    "                                decoding the range configured in utils.config file\n",
    "    \n",
    "    Returns:\n",
    "        mean(auc_scores): mean AUC score among all datasets for given hyperparameters\n",
    "        mean(accuracy_scores): mean accuracy score among all datasets for given hyperparameters\n",
    "        mean(f1_scores): mean F1 score among all datasets for given hyperparameters\n",
    "    \n",
    "    \"\"\"  \n",
    "    param = {param_name: utils.study_utils.sample_parameter(trial, param_name, value) for param_name, value in param_space.items()}\n",
    "    auc_scores = []\n",
    "\n",
    "    for X, y in zip(Xs, ys):\n",
    "        auc_split = []\n",
    "\n",
    "        for train_idx, val_idx in SKF.split(X, y):\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            model = model_class(**param)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            y_pred = model.predict(X_val)\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                y_pred_prob = model.predict_proba(X_val)[:, 1]\n",
    "            else:\n",
    "                y_pred_prob = y_pred\n",
    "\n",
    "            auc_split.append(roc_auc_score(y_val, y_pred_prob))\n",
    "\n",
    "        auc_scores.append(np.mean(np.array(auc_split)))\n",
    "\n",
    "    return np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T20:24:24.959590Z",
     "start_time": "2024-11-14T20:24:24.953372Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import study_utils\n",
    "\n",
    "def run_study(objective, model_class, sampler_class, Xs, ys, param_space, n_trials):\n",
    "    \"\"\"\n",
    "    Function that runs optuna optimization. It instantiates the sampler and starts a study\n",
    "    for given model_class with param_space and for given datasets Xs and ys.\n",
    "    \n",
    "    Args:\n",
    "        objective: the objective function to be optimized\n",
    "        model_class: class of the model to be optimized\n",
    "        sampler_class: class of the sampler to be used\n",
    "        Xs: list of Xs of the datasets\n",
    "        ys: list of ys of the datasets\n",
    "        param_space: dictionary of hyperparameters and their ranges\n",
    "        n_trials: number of trials for the optimization process\n",
    "        \n",
    "    Dependencies:\n",
    "        objective: function that is invoked in every iteration of the optimization process\n",
    "        get_trials: function that returns the trials (iterations) of the study\n",
    "    \"\"\"\n",
    "    # seeds = [SEED] if sampler_class.__name__ == 'RandomSampler' else SEEDS\n",
    "    seeds = [SEED]\n",
    "    n_trials = math.ceil(n_trials/len(seeds))\n",
    "    main_study = optuna.create_study(direction=\"maximize\")\n",
    "    \n",
    "    for seed in seeds:\n",
    "        sampler = sampler_class(seed=seed)\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "        study.optimize(lambda trial: objective(trial, model_class, Xs, ys, param_space), n_trials=n_trials)\n",
    "        main_study.add_trials(study.get_trials())\n",
    "    \n",
    "    print(main_study.best_trials)\n",
    "    trials = utils.study_utils.get_trials(main_study)\n",
    "    \n",
    "    return trials, main_study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating $\\theta^*$ - optimal defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - $\\theta^*$\n",
    "#### RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T20:24:25.003930Z",
     "start_time": "2024-11-14T20:24:25.001196Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-15 01:54:41,901] A new study created in memory with name: no-name-a9bb5b65-b725-4173-af30-6c7813461e2d\n",
      "[I 2024-11-15 01:54:41,920] A new study created in memory with name: no-name-96bf1db9-4c41-4fc3-98bd-ffb692c909d2\n",
      "[I 2024-11-15 01:54:42,347] Trial 0 finished with value: 0.8127931691379152 and parameters: {'C': 0.09915644566638401, 'penalty': 'elasticnet', 'l1_ratio': 0.6351221010640696, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.8127931691379152.\n",
      "[I 2024-11-15 01:54:46,431] Trial 1 finished with value: 0.8137264202663816 and parameters: {'C': 71.77141927992021, 'penalty': 'elasticnet', 'l1_ratio': 0.024810409748678097, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 1 with value: 0.8137264202663816.\n",
      "[I 2024-11-15 01:54:46,918] Trial 2 finished with value: 0.7933168868858801 and parameters: {'C': 0.0017707168643537846, 'penalty': 'elasticnet', 'l1_ratio': 0.0004207053950287938, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 1 with value: 0.8137264202663816.\n",
      "[I 2024-11-15 01:54:47,120] Trial 3 finished with value: 0.5580219924892761 and parameters: {'C': 0.00029152036385288323, 'penalty': 'elasticnet', 'l1_ratio': 0.29154431891537513, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 1 with value: 0.8137264202663816.\n",
      "[I 2024-11-15 01:54:48,491] Trial 4 finished with value: 0.8141319971606495 and parameters: {'C': 6.4405075539937195, 'penalty': 'elasticnet', 'l1_ratio': 0.06796578090758151, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 4 with value: 0.8141319971606495.\n",
      "[I 2024-11-15 01:54:48,590] Trial 5 finished with value: 0.5 and parameters: {'C': 0.00014610865886287216, 'penalty': 'elasticnet', 'l1_ratio': 0.7579479953348001, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 4 with value: 0.8141319971606495.\n",
      "[I 2024-11-15 01:54:56,513] Trial 6 finished with value: 0.8136961418510222 and parameters: {'C': 456.6054873446131, 'penalty': 'elasticnet', 'l1_ratio': 0.0007068974950624604, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 4 with value: 0.8141319971606495.\n",
      "[I 2024-11-15 01:54:56,795] Trial 7 finished with value: 0.7984651901710494 and parameters: {'C': 0.002848391870910803, 'penalty': 'elasticnet', 'l1_ratio': 0.0005415244119402539, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 4 with value: 0.8141319971606495.\n",
      "[I 2024-11-15 01:54:57,144] Trial 8 finished with value: 0.8137440004907148 and parameters: {'C': 0.027160511446548512, 'penalty': 'elasticnet', 'l1_ratio': 0.012561043700013555, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 4 with value: 0.8141319971606495.\n",
      "[I 2024-11-15 01:54:57,620] Trial 9 finished with value: 0.8159293896091279 and parameters: {'C': 0.2854697857797185, 'penalty': 'elasticnet', 'l1_ratio': 0.0014618962793704966, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 9 with value: 0.8159293896091279.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=9, state=TrialState.COMPLETE, values=[0.8159293896091279], datetime_start=datetime.datetime(2024, 11, 15, 1, 54, 57, 144921), datetime_complete=datetime.datetime(2024, 11, 15, 1, 54, 57, 620265), params={'C': 0.2854697857797185, 'penalty': 'elasticnet', 'l1_ratio': 0.0014618962793704966, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'C': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'penalty': CategoricalDistribution(choices=('elasticnet',)), 'l1_ratio': FloatDistribution(high=1.0, log=True, low=0.0001, step=None), 'class_weight': CategoricalDistribution(choices=('balanced',)), 'max_iter': IntDistribution(high=1500, log=False, low=1500, step=1), 'solver': CategoricalDistribution(choices=('saga',))}, trial_id=9, value=None)]\n",
      "Best params for Logistic Regression \n",
      "C :  0.2854697857797185\n",
      "penalty :  elasticnet\n",
      "l1_ratio :  0.0014618962793704966\n",
      "class_weight :  balanced\n",
      "max_iter :  1500\n",
      "solver :  saga\n"
     ]
    }
   ],
   "source": [
    "model = MODELS[0][0]\n",
    "param_grid = MODELS[0][1]\n",
    "sampler = SAMPLERS[0]\n",
    "\n",
    "lr_joint_trials, lr_joint_study = run_experiment_joint(model, sampler, Xs, ys, param_grid, results_dir, n_trials=300)\n",
    "\n",
    "lr_best_params_joint = lr_joint_study.best_trials[0].params\n",
    "print(\"Best params for Logistic Regression \")\n",
    "for param_name, value in lr_best_params_joint.items():\n",
    "    print(param_name, \": \", value)\n",
    "\n",
    "save_study_to_pickle_joint(lr_joint_study, 'lr_rs')\n",
    "save_best_params_to_json_joint(lr_best_params_joint, 'lr_rs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T20:24:25.051935Z",
     "start_time": "2024-11-14T20:24:25.049226Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-15 01:56:55,734] A new study created in memory with name: no-name-f854c53b-2679-433c-9d3e-fe81c9f49d3a\n",
      "[I 2024-11-15 01:56:55,741] A new study created in memory with name: no-name-c46d9fc3-c260-4aed-9725-786ece895b4f\n",
      "[I 2024-11-15 01:56:56,118] Trial 0 finished with value: 0.8127854164971388 and parameters: {'C': 0.09915644566638401, 'penalty': 'elasticnet', 'l1_ratio': 0.6351221010640696, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.8127854164971388.\n",
      "[I 2024-11-15 01:57:00,180] Trial 1 finished with value: 0.8137162203727448 and parameters: {'C': 71.77141927992021, 'penalty': 'elasticnet', 'l1_ratio': 0.024810409748678097, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 1 with value: 0.8137162203727448.\n",
      "[I 2024-11-15 01:57:00,455] Trial 2 finished with value: 0.7933232970047078 and parameters: {'C': 0.0017707168643537846, 'penalty': 'elasticnet', 'l1_ratio': 0.0004207053950287938, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 1 with value: 0.8137162203727448.\n",
      "[I 2024-11-15 01:57:00,632] Trial 3 finished with value: 0.5580219924892761 and parameters: {'C': 0.00029152036385288323, 'penalty': 'elasticnet', 'l1_ratio': 0.29154431891537513, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 1 with value: 0.8137162203727448.\n",
      "[I 2024-11-15 01:57:02,094] Trial 4 finished with value: 0.8141660767253895 and parameters: {'C': 6.4405075539937195, 'penalty': 'elasticnet', 'l1_ratio': 0.06796578090758151, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 4 with value: 0.8141660767253895.\n",
      "[I 2024-11-15 01:57:02,199] Trial 5 finished with value: 0.5 and parameters: {'C': 0.00014610865886287216, 'penalty': 'elasticnet', 'l1_ratio': 0.7579479953348001, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 4 with value: 0.8141660767253895.\n",
      "[I 2024-11-15 01:57:09,969] Trial 6 finished with value: 0.8137055758132865 and parameters: {'C': 456.6054873446131, 'penalty': 'elasticnet', 'l1_ratio': 0.0007068974950624604, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 4 with value: 0.8141660767253895.\n",
      "[I 2024-11-15 01:57:10,242] Trial 7 finished with value: 0.7984617675031535 and parameters: {'C': 0.002848391870910803, 'penalty': 'elasticnet', 'l1_ratio': 0.0005415244119402539, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 4 with value: 0.8141660767253895.\n",
      "[I 2024-11-15 01:57:10,549] Trial 8 finished with value: 0.8137435382004691 and parameters: {'C': 0.027160511446548512, 'penalty': 'elasticnet', 'l1_ratio': 0.012561043700013555, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 4 with value: 0.8141660767253895.\n",
      "[I 2024-11-15 01:57:11,049] Trial 9 finished with value: 0.8159482164618372 and parameters: {'C': 0.2854697857797185, 'penalty': 'elasticnet', 'l1_ratio': 0.0014618962793704966, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 9 with value: 0.8159482164618372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=9, state=TrialState.COMPLETE, values=[0.8159482164618372], datetime_start=datetime.datetime(2024, 11, 15, 1, 57, 10, 550240), datetime_complete=datetime.datetime(2024, 11, 15, 1, 57, 11, 49140), params={'C': 0.2854697857797185, 'penalty': 'elasticnet', 'l1_ratio': 0.0014618962793704966, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'C': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'penalty': CategoricalDistribution(choices=('elasticnet',)), 'l1_ratio': FloatDistribution(high=1.0, log=True, low=0.0001, step=None), 'class_weight': CategoricalDistribution(choices=('balanced',)), 'max_iter': IntDistribution(high=1500, log=False, low=1500, step=1), 'solver': CategoricalDistribution(choices=('saga',))}, trial_id=9, value=None)]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m sampler \u001b[38;5;241m=\u001b[39m SAMPLERS[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      5\u001b[0m lr_joint_trials_bs, lr_joint_study_bs \u001b[38;5;241m=\u001b[39m run_experiment_joint(model, sampler, Xs, ys, param_grid, results_dir, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m lr_best_params_joint_bs \u001b[38;5;241m=\u001b[39m \u001b[43mlr_joint_study_bs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_trials\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest params for Logistic Regression \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_name, value \u001b[38;5;129;01min\u001b[39;00m lr_best_params_joint_bs\u001b[38;5;241m.\u001b[39mitems():\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'params'"
     ]
    }
   ],
   "source": [
    "model = MODELS[0][0]\n",
    "param_grid = MODELS[0][1]\n",
    "sampler = SAMPLERS[1]\n",
    "\n",
    "lr_joint_trials_bs, lr_joint_study_bs = run_experiment_joint(model, sampler, Xs, ys, param_grid, results_dir, n_trials=150)\n",
    "\n",
    "lr_best_params_joint_bs = lr_joint_study_bs.best_trials[0].params\n",
    "print(\"Best params for Logistic Regression \")\n",
    "for param_name, value in lr_best_params_joint_bs.items():\n",
    "    print(param_name, \": \", value)\n",
    "\n",
    "save_study_to_pickle_joint(lr_joint_study_bs, 'lr_tpe')\n",
    "save_best_params_to_json_joint(lr_best_params_joint_bs, 'lr_tpe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTrees - $\\theta^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T20:02:20.950851Z",
     "start_time": "2024-11-14T20:00:31.001204Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 21:00:31,003 - __main__ - INFO - Searching hyperparameter space with RandomSampler for ExtraTreesClassifier\n",
      "2024-11-14 21:00:31,005 - __main__ - INFO - Optimizing hyperparameters for all datasets simultaneously to calculate optimal defaults\n",
      "[I 2024-11-14 21:00:31,005] A new study created in memory with name: no-name-d17ab06d-dc96-4b67-8c16-f2a446720461\n",
      "[I 2024-11-14 21:00:31,007] A new study created in memory with name: no-name-b3df6857-1553-4bd6-8df2-5ccfedb281c3\n",
      "[I 2024-11-14 21:00:39,370] Trial 0 finished with value: 0.7785188562284511 and parameters: {'n_estimators': 381, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.5780093202212182, 'max_features': 0.22479561626896213, 'min_samples_leaf': 0.061616722433639894}. Best is trial 0 with value: 0.7785188562284511.\n",
      "[I 2024-11-14 21:01:11,389] Trial 1 finished with value: 0.7841143724007601 and parameters: {'n_estimators': 868, 'criterion': 'entropy', 'bootstrap': True, 'max_samples': 0.9849549260809971, 'max_features': 0.7659541126403374, 'min_samples_leaf': 0.09246782213565524}. Best is trial 1 with value: 0.7841143724007601.\n",
      "[I 2024-11-14 21:01:15,242] Trial 2 finished with value: 0.75224787541908 and parameters: {'n_estimators': 190, 'criterion': 'log_loss', 'bootstrap': True, 'max_samples': 0.7159725093210578, 'max_features': 0.3329833121584336, 'min_samples_leaf': 0.17237057894447588}. Best is trial 1 with value: 0.7841143724007601.\n",
      "[I 2024-11-14 21:01:18,318] Trial 3 finished with value: 0.7653490403664827 and parameters: {'n_estimators': 148, 'criterion': 'log_loss', 'bootstrap': True, 'max_samples': 0.8925879806965068, 'max_features': 0.25973902572668783, 'min_samples_leaf': 0.1528468876827223}. Best is trial 1 with value: 0.7841143724007601.\n",
      "[I 2024-11-14 21:01:38,397] Trial 4 finished with value: 0.5 and parameters: {'n_estimators': 597, 'criterion': 'entropy', 'bootstrap': True, 'max_samples': 0.5325257964926398, 'max_features': 0.8591084298026667, 'min_samples_leaf': 0.24312640661491186}. Best is trial 1 with value: 0.7841143724007601.\n",
      "[I 2024-11-14 21:02:01,771] Trial 5 finished with value: 0.7603147279852903 and parameters: {'n_estimators': 811, 'criterion': 'log_loss', 'bootstrap': True, 'max_samples': 0.7200762468698007, 'max_features': 0.19763058787582308, 'min_samples_leaf': 0.14903538202225403}. Best is trial 1 with value: 0.7841143724007601.\n",
      "[I 2024-11-14 21:02:04,140] Trial 6 finished with value: 0.7540015710572991 and parameters: {'n_estimators': 44, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.6558555380447055, 'max_features': 0.5160544169422486, 'min_samples_leaf': 0.15934205586865594}. Best is trial 1 with value: 0.7841143724007601.\n",
      "[I 2024-11-14 21:02:11,725] Trial 7 finished with value: 0.7525070377643577 and parameters: {'n_estimators': 193, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.9474136752138245, 'max_features': 0.5783199830488681, 'min_samples_leaf': 0.23437484700462335}. Best is trial 1 with value: 0.7841143724007601.\n",
      "[I 2024-11-14 21:02:13,765] Trial 8 finished with value: 0.7051110057091214 and parameters: {'n_estimators': 97, 'criterion': 'log_loss', 'bootstrap': True, 'max_samples': 0.6943386448447411, 'max_features': 0.3170792254191167, 'min_samples_leaf': 0.21574750183038588}. Best is trial 1 with value: 0.7841143724007601.\n",
      "[I 2024-11-14 21:02:20,935] Trial 9 finished with value: 0.7325652209679858 and parameters: {'n_estimators': 363, 'criterion': 'entropy', 'bootstrap': True, 'max_samples': 0.9010984903770198, 'max_features': 0.15964051494381667, 'min_samples_leaf': 0.24737738732010345}. Best is trial 1 with value: 0.7841143724007601.\n",
      "2024-11-14 21:02:20,947 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/ExtraTreesClassifier_RandomSampler_joint.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.7841143724007601], datetime_start=datetime.datetime(2024, 11, 14, 21, 0, 39, 371261), datetime_complete=datetime.datetime(2024, 11, 14, 21, 1, 11, 389653), params={'n_estimators': 868, 'criterion': 'entropy', 'bootstrap': True, 'max_samples': 0.9849549260809971, 'max_features': 0.7659541126403374, 'min_samples_leaf': 0.09246782213565524}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=1000, log=False, low=10, step=1), 'criterion': CategoricalDistribution(choices=('gini', 'entropy', 'log_loss')), 'bootstrap': CategoricalDistribution(choices=(True,)), 'max_samples': FloatDistribution(high=1.0, log=False, low=0.5, step=None), 'max_features': FloatDistribution(high=0.9, log=False, low=0.1, step=None), 'min_samples_leaf': FloatDistribution(high=0.25, log=False, low=0.05, step=None)}, trial_id=1, value=None)]\n",
      "Best params for Extra Trees \n",
      "n_estimators :  868\n",
      "criterion :  entropy\n",
      "bootstrap :  True\n",
      "max_samples :  0.9849549260809971\n",
      "max_features :  0.7659541126403374\n",
      "min_samples_leaf :  0.09246782213565524\n"
     ]
    }
   ],
   "source": [
    "model = MODELS[1][0]\n",
    "param_grid = MODELS[1][1]\n",
    "sampler = SAMPLERS[0]\n",
    "\n",
    "# Run the optimization process for all datasets simultaneously\n",
    "et_joint_trials, et_joint_study = run_experiment_joint(model, sampler, Xs, ys, param_grid, results_dir, n_trials=300)\n",
    "\n",
    "# Get best default hyperparameters\n",
    "et_best_params_joint = et_joint_study.best_trials[0].params\n",
    "print(\"Best params for Extra Trees \")\n",
    "for param_name, value in et_best_params_joint.items():\n",
    "    print(param_name, \": \", value)\n",
    "\n",
    "# Save the study and best parameters to pickle files\n",
    "save_study_to_pickle_joint(et_joint_study, 'et_rs')\n",
    "save_best_params_to_json_joint(et_best_params_joint, 'et_rs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T23:42:12.912013Z",
     "start_time": "2024-11-13T23:40:48.172820Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 00:40:48,176 - __main__ - INFO - Searching hyperparameter space with TPESampler for ExtraTreesClassifier\n",
      "2024-11-14 00:40:48,179 - __main__ - INFO - Optimizing hyperparameters for all datasets simultaneously to calculate optimal defaults\n",
      "[I 2024-11-14 00:40:48,180] A new study created in memory with name: no-name-1fcd5c28-a83d-4567-8a6a-ed98b3da1269\n",
      "[I 2024-11-14 00:40:48,182] A new study created in memory with name: no-name-7ee14757-28f3-4ce1-a500-24414ae89e8d\n",
      "[I 2024-11-14 00:41:03,828] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 574, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.24041677639819287, 'max_features': 0.2403950683025824, 'min_samples_leaf': 0.15227525095137953}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:41:50,265] Trial 1 finished with value: 0.708489178383457 and parameters: {'n_estimators': 1302, 'criterion': 'entropy', 'bootstrap': True, 'max_samples': 0.9729188669457949, 'max_features': 0.8491983767203796, 'min_samples_leaf': 0.29110519961044856}. Best is trial 1 with value: 0.708489178383457.\n",
      "[I 2024-11-14 00:41:50,266] A new study created in memory with name: no-name-d7a9030c-06b9-4d56-9677-199ba0ecc7b1\n",
      "[I 2024-11-14 00:41:59,383] Trial 0 finished with value: 0.7335389282170084 and parameters: {'n_estimators': 458, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.6052140781935152, 'max_features': 0.32823005879811984, 'min_samples_leaf': 0.19447937531659815}. Best is trial 0 with value: 0.7335389282170084.\n",
      "[I 2024-11-14 00:42:01,522] Trial 1 finished with value: 0.5 and parameters: {'n_estimators': 106, 'criterion': 'log_loss', 'bootstrap': True, 'max_samples': 0.8090866526479393, 'max_features': 0.1687386883542335, 'min_samples_leaf': 0.3859125369579679}. Best is trial 0 with value: 0.7335389282170084.\n",
      "[I 2024-11-14 00:42:01,523] A new study created in memory with name: no-name-b91c6093-48bc-4c9d-a2a3-3a84657f6f40\n",
      "[I 2024-11-14 00:42:10,699] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 487, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.8813498313568406, 'max_features': 0.6667556660442842, 'min_samples_leaf': 0.41726683712558366}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:42:12,902] Trial 1 finished with value: 0.5 and parameters: {'n_estimators': 120, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.15116639624139466, 'max_features': 0.3134189797553236, 'min_samples_leaf': 0.3118633033493464}. Best is trial 0 with value: 0.5.\n",
      "2024-11-14 00:42:12,908 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/ExtraTreesClassifier_TPESampler_joint.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=2, state=1, values=[0.7335389282170084], datetime_start=datetime.datetime(2024, 11, 14, 0, 41, 50, 267254), datetime_complete=datetime.datetime(2024, 11, 14, 0, 41, 59, 383341), params={'n_estimators': 458, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.6052140781935152, 'max_features': 0.32823005879811984, 'min_samples_leaf': 0.19447937531659815}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=1500, log=False, low=20, step=1), 'criterion': CategoricalDistribution(choices=('gini', 'entropy', 'log_loss')), 'bootstrap': CategoricalDistribution(choices=(True,)), 'max_samples': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'max_features': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'min_samples_leaf': FloatDistribution(high=1.0, log=False, low=0.1, step=None)}, trial_id=2, value=None)]\n",
      "Best params for Extra Trees \n",
      "n_estimators :  458\n",
      "criterion :  gini\n",
      "bootstrap :  True\n",
      "max_samples :  0.6052140781935152\n",
      "max_features :  0.32823005879811984\n",
      "min_samples_leaf :  0.19447937531659815\n"
     ]
    }
   ],
   "source": [
    "model = MODELS[1][0]\n",
    "param_grid = MODELS[1][1]\n",
    "sampler = SAMPLERS[1]\n",
    "\n",
    "# Run the optimization process for all datasets simultaneously\n",
    "et_joint_trials, et_joint_study = run_experiment_joint(model, sampler, Xs, ys, param_grid, results_dir, n_trials=150)\n",
    "\n",
    "# Get best default hyperparameters\n",
    "et_best_params_joint = et_joint_study.best_trials[0].params\n",
    "\n",
    "print(\"Best params for Extra Trees \")\n",
    "for param_name, value in et_best_params_joint.items():\n",
    "    print(param_name, \": \", value)\n",
    "    \n",
    "# Save the study and best parameters to pickle files\n",
    "save_study_to_pickle_joint(et_joint_study, 'et_tpe')\n",
    "save_best_params_to_json_joint(et_best_params_joint, 'et_tpe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost - $\\theta^*$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T20:17:45.918923Z",
     "start_time": "2024-11-14T20:17:18.389365Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 21:17:18,392 - __main__ - INFO - Searching hyperparameter space with RandomSampler for XGBClassifier\n",
      "2024-11-14 21:17:18,394 - __main__ - INFO - Optimizing hyperparameters for all datasets simultaneously to calculate optimal defaults\n",
      "[I 2024-11-14 21:17:18,395] A new study created in memory with name: no-name-74554863-229e-4f21-845f-e6d8e1eb65fb\n",
      "[I 2024-11-14 21:17:18,396] A new study created in memory with name: no-name-affc9caa-3890-4e5e-9b3b-696e61d46a77\n",
      "[I 2024-11-14 21:17:23,740] Trial 0 finished with value: 0.658821131497315 and parameters: {'n_estimators': 755, 'learning_rate': 0.2657846934562037, 'subsample': 0.7989954563585538, 'booster': 'gbtree', 'max_depth': 9, 'min_child_weight': 20.814367336189438, 'colsample_bytree': 0.2403950683025824, 'colsample_bylevel': 0.15227525095137953, 'reg_alpha': 64.77532426827341, 'reg_lambda': 4.0428727350273315}. Best is trial 0 with value: 0.658821131497315.\n",
      "[I 2024-11-14 21:17:36,015] Trial 1 finished with value: 0.8089259977343646 and parameters: {'n_estimators': 1419, 'learning_rate': 0.00011861690371243162, 'subsample': 0.9774323891214958, 'booster': 'gbtree', 'max_depth': 13, 'min_child_weight': 27.967067056141072, 'colsample_bytree': 0.26364247048639056, 'colsample_bylevel': 0.2650640588680905, 'reg_alpha': 0.010996218010237245, 'reg_lambda': 1.40779231399724}. Best is trial 1 with value: 0.8089259977343646.\n",
      "[I 2024-11-14 21:17:40,292] Trial 2 finished with value: 0.795590321840242 and parameters: {'n_estimators': 870, 'learning_rate': 0.0011195018979975153, 'subsample': 0.7088896710417846, 'booster': 'gbtree', 'max_depth': 3, 'min_child_weight': 38.1023703639727, 'colsample_bytree': 0.4297256589643226, 'colsample_bylevel': 0.5104629857953323, 'reg_alpha': 18.533502111715695, 'reg_lambda': 0.01577766363058246}. Best is trial 1 with value: 0.8089259977343646.\n",
      "[I 2024-11-14 21:17:43,566] Trial 3 finished with value: 0.5 and parameters: {'n_estimators': 1033, 'learning_rate': 0.013611714042498597, 'subsample': 0.28483780953999827, 'booster': 'gbtree', 'max_depth': 10, 'min_child_weight': 22.656563708286026, 'colsample_bytree': 0.1585464336867516, 'colsample_bylevel': 0.9539969835279999, 'reg_alpha': 301.0828323371717, 'reg_lambda': 70.85721663941601}. Best is trial 1 with value: 0.8089259977343646.\n",
      "[I 2024-11-14 21:17:45,895] Trial 4 finished with value: 0.6523348622508344 and parameters: {'n_estimators': 616, 'learning_rate': 0.00022481268581995073, 'subsample': 0.7631747698841177, 'booster': 'gbtree', 'max_depth': 7, 'min_child_weight': 16.49885582528691, 'colsample_bytree': 0.5456592191001431, 'colsample_bylevel': 0.13094966900369656, 'reg_alpha': 126.14674784489826, 'reg_lambda': 0.035700959600309494}. Best is trial 1 with value: 0.8089259977343646.\n",
      "2024-11-14 21:17:45,915 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/XGBClassifier_RandomSampler_joint.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.8089259977343646], datetime_start=datetime.datetime(2024, 11, 14, 21, 17, 23, 741520), datetime_complete=datetime.datetime(2024, 11, 14, 21, 17, 36, 15654), params={'n_estimators': 1419, 'learning_rate': 0.00011861690371243162, 'subsample': 0.9774323891214958, 'booster': 'gbtree', 'max_depth': 13, 'min_child_weight': 27.967067056141072, 'colsample_bytree': 0.26364247048639056, 'colsample_bylevel': 0.2650640588680905, 'reg_alpha': 0.010996218010237245, 'reg_lambda': 1.40779231399724}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=2000, log=False, low=10, step=1), 'learning_rate': FloatDistribution(high=0.4, log=True, low=0.0001, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.25, step=None), 'booster': CategoricalDistribution(choices=('gbtree',)), 'max_depth': IntDistribution(high=15, log=False, low=1, step=1), 'min_child_weight': FloatDistribution(high=128.0, log=False, low=1.0, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'colsample_bylevel': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'reg_alpha': FloatDistribution(high=512.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=1000.0, log=True, low=0.001, step=None)}, trial_id=1, value=None)]\n",
      "Best params for XGBoost \n",
      "n_estimators :  1419\n",
      "learning_rate :  0.00011861690371243162\n",
      "subsample :  0.9774323891214958\n",
      "booster :  gbtree\n",
      "max_depth :  13\n",
      "min_child_weight :  27.967067056141072\n",
      "colsample_bytree :  0.26364247048639056\n",
      "colsample_bylevel :  0.2650640588680905\n",
      "reg_alpha :  0.010996218010237245\n",
      "reg_lambda :  1.40779231399724\n"
     ]
    }
   ],
   "source": [
    "model = MODELS[2][0]\n",
    "param_grid = MODELS[2][1]\n",
    "sampler = SAMPLERS[0]\n",
    "\n",
    "# Run the optimization process for all datasets simultaneously\n",
    "xgb_joint_trials, xgb_joint_study = run_experiment_joint(model, sampler, Xs, ys, param_grid, results_dir, n_trials=300)\n",
    "\n",
    "# Get best default hyperparameters\n",
    "xgb_best_params_joint = xgb_joint_study.best_trials[0].params\n",
    "print(\"Best params for XGBoost \")\n",
    "for param_name, value in xgb_best_params_joint.items():\n",
    "    print(param_name, \": \", value)\n",
    "\n",
    "# Save the study and best parameters to pickle files\n",
    "save_study_to_pickle_joint(xgb_joint_study, 'xgb_rs')\n",
    "save_best_params_to_json_joint(xgb_best_params_joint, 'xgb_rs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T23:44:54.186065Z",
     "start_time": "2024-11-13T23:43:22.636782Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 00:43:22,638 - __main__ - INFO - Searching hyperparameter space with TPESampler for XGBClassifier\n",
      "2024-11-14 00:43:22,640 - __main__ - INFO - Optimizing hyperparameters for all datasets simultaneously to calculate optimal defaults\n",
      "[I 2024-11-14 00:43:22,641] A new study created in memory with name: no-name-068a0c3f-6ebb-4b4b-a4cf-dba363fa193c\n",
      "[I 2024-11-14 00:43:22,642] A new study created in memory with name: no-name-ee6ac0a8-95fa-4a2f-b74c-80d7c9692978\n",
      "[I 2024-11-14 00:43:32,742] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 1873, 'learning_rate': 0.1804941906677887, 'subsample': 0.7587945476302645, 'booster': 'gbtree', 'max_depth': 9, 'min_child_weight': 20.814367336189438, 'colsample_bytree': 0.16443457513284063, 'colsample_bylevel': 0.06750277604651747, 'reg_alpha': 849.9808989183019, 'reg_lambda': 6.4405075539937195}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:44:01,741] Trial 1 finished with value: 0.8083940908272287 and parameters: {'n_estimators': 3541, 'learning_rate': 1.236400798668794e-05, 'subsample': 0.9729188669457949, 'booster': 'gbtree', 'max_depth': 13, 'min_child_weight': 27.967067056141072, 'colsample_bytree': 0.19000671753502962, 'colsample_bylevel': 0.1915704647548995, 'reg_alpha': 0.027160511446548512, 'reg_lambda': 1.5777981883365035}. Best is trial 1 with value: 0.8083940908272287.\n",
      "[I 2024-11-14 00:44:01,744] A new study created in memory with name: no-name-17743e6f-15d6-4217-8723-84ca7a837a66\n",
      "[I 2024-11-14 00:44:08,459] Trial 0 finished with value: 0.6588267411829274 and parameters: {'n_estimators': 1482, 'learning_rate': 0.041907742461594774, 'subsample': 0.4152272727010703, 'booster': 'gbtree', 'max_depth': 12, 'min_child_weight': 72.29131992286271, 'colsample_bytree': 0.2610530646779318, 'colsample_bylevel': 0.11392731284825795, 'reg_alpha': 0.0002935525339557525, 'reg_lambda': 24.341035298636815}. Best is trial 0 with value: 0.6588267411829274.\n",
      "[I 2024-11-14 00:44:27,373] Trial 1 finished with value: 0.8096246235110756 and parameters: {'n_estimators': 3490, 'learning_rate': 0.019087949022263857, 'subsample': 0.8090866526479393, 'booster': 'gbtree', 'max_depth': 2, 'min_child_weight': 41.34543577073546, 'colsample_bytree': 0.7436130444117905, 'colsample_bylevel': 0.33520928688329754, 'reg_alpha': 0.5769841450775586, 'reg_lambda': 0.002809866857880845}. Best is trial 1 with value: 0.8096246235110756.\n",
      "[I 2024-11-14 00:44:27,375] A new study created in memory with name: no-name-97764d38-af4c-4836-978b-f8485b11c8b3\n",
      "[I 2024-11-14 00:44:34,942] Trial 0 finished with value: 0.5813790745377854 and parameters: {'n_estimators': 1579, 'learning_rate': 0.0010672674697233477, 'subsample': 0.34028403750096586, 'booster': 'gbtree', 'max_depth': 2, 'min_child_weight': 111.25714286924307, 'colsample_bytree': 0.6334312326487125, 'colsample_bylevel': 0.35899352083814196, 'reg_alpha': 0.00034697708562294216, 'reg_lambda': 10.251908819044953}. Best is trial 0 with value: 0.5813790745377854.\n",
      "[I 2024-11-14 00:44:54,174] Trial 1 finished with value: 0.6460003042694724 and parameters: {'n_estimators': 2994, 'learning_rate': 2.5874252676661356e-05, 'subsample': 0.15116639624139466, 'booster': 'gbtree', 'max_depth': 4, 'min_child_weight': 30.89626613929666, 'colsample_bytree': 0.7766276682482396, 'colsample_bylevel': 0.052175119754174874, 'reg_alpha': 0.06879584856239142, 'reg_lambda': 0.5666734024826726}. Best is trial 1 with value: 0.6460003042694724.\n",
      "2024-11-14 00:44:54,182 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/XGBClassifier_TPESampler_joint.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=3, state=1, values=[0.8096246235110756], datetime_start=datetime.datetime(2024, 11, 14, 0, 44, 8, 460569), datetime_complete=datetime.datetime(2024, 11, 14, 0, 44, 27, 373370), params={'n_estimators': 3490, 'learning_rate': 0.019087949022263857, 'subsample': 0.8090866526479393, 'booster': 'gbtree', 'max_depth': 2, 'min_child_weight': 41.34543577073546, 'colsample_bytree': 0.7436130444117905, 'colsample_bylevel': 0.33520928688329754, 'reg_alpha': 0.5769841450775586, 'reg_lambda': 0.002809866857880845}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=5000, log=False, low=1, step=1), 'learning_rate': FloatDistribution(high=0.3, log=True, low=1e-05, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'booster': CategoricalDistribution(choices=('gbtree',)), 'max_depth': IntDistribution(high=15, log=False, low=1, step=1), 'min_child_weight': FloatDistribution(high=128.0, log=False, low=1.0, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'colsample_bylevel': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'reg_alpha': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None)}, trial_id=3, value=None)]\n",
      "Best params for XGBoost \n",
      "n_estimators :  3490\n",
      "learning_rate :  0.019087949022263857\n",
      "subsample :  0.8090866526479393\n",
      "booster :  gbtree\n",
      "max_depth :  2\n",
      "min_child_weight :  41.34543577073546\n",
      "colsample_bytree :  0.7436130444117905\n",
      "colsample_bylevel :  0.33520928688329754\n",
      "reg_alpha :  0.5769841450775586\n",
      "reg_lambda :  0.002809866857880845\n"
     ]
    }
   ],
   "source": [
    "model = MODELS[2][0]\n",
    "param_grid = MODELS[2][1]\n",
    "sampler = SAMPLERS[1]\n",
    "\n",
    "# Run the optimization process for all datasets simultaneously\n",
    "xgb_joint_trials, xgb_joint_study = run_experiment_joint(model, sampler, Xs, ys, param_grid, results_dir, n_trials=150)\n",
    "\n",
    "# Get best default hyperparameters\n",
    "xgb_best_params_joint = xgb_joint_study.best_trials[0].params\n",
    "\n",
    "print(\"Best params for XGBoost \")\n",
    "for param_name, value in xgb_best_params_joint.items():\n",
    "    print(param_name, \": \", value)\n",
    "    \n",
    "# Save the study and best parameters to pickle files\n",
    "save_study_to_pickle_joint(xgb_joint_study, 'xgb_tpe')\n",
    "save_best_params_to_json_joint(xgb_best_params_joint, 'xgb_tpe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization of each dataset separately to calculate $\\theta^{(j)*}$ - best hyperparameters for given dataset $(j)$\n",
    "\n",
    "Acknowledgements:\n",
    "- From now on we will use AUC as our primary metric. All performance measures and tunability values will be caluclated using AUC\n",
    "- Optimization will be performed in 2 chunks - first using Random Search and then using TPE (form of bayesian optimization)\n",
    "- For each chunk we perform marginal optimization over all models and datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization with RandomSearch - LogisticRegression, ExtraTrees and XGBoost at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T23:47:02.036203Z",
     "start_time": "2024-11-13T23:44:54.222118Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 00:44:54,225 - __main__ - INFO - Searching hyperparameter space with RandomSampler for LogisticRegression\n",
      "2024-11-14 00:44:54,226 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 31\n",
      "[I 2024-11-14 00:44:54,227] A new study created in memory with name: no-name-45f2ad2b-8e48-4865-a5e2-f2f1a3c578aa\n",
      "[I 2024-11-14 00:44:54,228] A new study created in memory with name: no-name-dc65ea21-59a9-41bd-952a-12dd056e12cf\n",
      "[I 2024-11-14 00:44:54,415] Trial 0 finished with value: 0.7788095238095238 and parameters: {'C': 0.09915644566638401, 'penalty': 'elasticnet', 'l1_ratio': 0.6351221010640696, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.7788095238095238.\n",
      "[I 2024-11-14 00:44:55,649] Trial 1 finished with value: 0.7803809523809524 and parameters: {'C': 71.77141927992021, 'penalty': 'elasticnet', 'l1_ratio': 0.024810409748678097, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 1 with value: 0.7803809523809524.\n",
      "[I 2024-11-14 00:44:55,777] Trial 2 finished with value: 0.749095238095238 and parameters: {'C': 0.0017707168643537846, 'penalty': 'elasticnet', 'l1_ratio': 0.0004207053950287938, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 1 with value: 0.7803809523809524.\n",
      "2024-11-14 00:44:55,788 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/LogisticRegression_RandomSampler_marginal_31.csv\n",
      "2024-11-14 00:44:55,790 - __main__ - INFO - Searching hyperparameter space with RandomSampler for LogisticRegression\n",
      "2024-11-14 00:44:55,790 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 37\n",
      "[I 2024-11-14 00:44:55,791] A new study created in memory with name: no-name-f830ee72-cd54-4648-94bf-a096d38ddbfa\n",
      "[I 2024-11-14 00:44:55,792] A new study created in memory with name: no-name-cc1970e8-30e9-448d-b9bc-21f2511e7d43\n",
      "[I 2024-11-14 00:44:55,843] Trial 0 finished with value: 0.8299594689028652 and parameters: {'C': 0.09915644566638401, 'penalty': 'elasticnet', 'l1_ratio': 0.6351221010640696, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.8299594689028652.\n",
      "[I 2024-11-14 00:44:55,894] Trial 1 finished with value: 0.8297638015373865 and parameters: {'C': 71.77141927992021, 'penalty': 'elasticnet', 'l1_ratio': 0.024810409748678097, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.8299594689028652.\n",
      "[I 2024-11-14 00:44:55,941] Trial 2 finished with value: 0.8164982529699512 and parameters: {'C': 0.0017707168643537846, 'penalty': 'elasticnet', 'l1_ratio': 0.0004207053950287938, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.8299594689028652.\n",
      "2024-11-14 00:44:55,950 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/LogisticRegression_RandomSampler_marginal_37.csv\n",
      "2024-11-14 00:44:55,952 - __main__ - INFO - Searching hyperparameter space with RandomSampler for LogisticRegression\n",
      "2024-11-14 00:44:55,952 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 45062\n",
      "[I 2024-11-14 00:44:55,953] A new study created in memory with name: no-name-714e1816-7b67-458d-8801-200477ccaea3\n",
      "[I 2024-11-14 00:44:55,954] A new study created in memory with name: no-name-5595e6a1-db6e-4cad-85d9-90a325e13960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.7803809523809524], datetime_start=datetime.datetime(2024, 11, 14, 0, 44, 54, 416069), datetime_complete=datetime.datetime(2024, 11, 14, 0, 44, 55, 649262), params={'C': 71.77141927992021, 'penalty': 'elasticnet', 'l1_ratio': 0.024810409748678097, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'C': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'penalty': CategoricalDistribution(choices=('elasticnet',)), 'l1_ratio': FloatDistribution(high=1.0, log=True, low=0.0001, step=None), 'class_weight': CategoricalDistribution(choices=('balanced',)), 'max_iter': IntDistribution(high=1500, log=False, low=1500, step=1), 'solver': CategoricalDistribution(choices=('saga',))}, trial_id=1, value=None)]\n",
      "[FrozenTrial(number=0, state=1, values=[0.8299594689028652], datetime_start=datetime.datetime(2024, 11, 14, 0, 44, 55, 793626), datetime_complete=datetime.datetime(2024, 11, 14, 0, 44, 55, 843339), params={'C': 0.09915644566638401, 'penalty': 'elasticnet', 'l1_ratio': 0.6351221010640696, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'C': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'penalty': CategoricalDistribution(choices=('elasticnet',)), 'l1_ratio': FloatDistribution(high=1.0, log=True, low=0.0001, step=None), 'class_weight': CategoricalDistribution(choices=('balanced',)), 'max_iter': IntDistribution(high=1500, log=False, low=1500, step=1), 'solver': CategoricalDistribution(choices=('saga',))}, trial_id=0, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:44:56,486] Trial 0 finished with value: 0.8324682639918153 and parameters: {'C': 0.09915644566638401, 'penalty': 'elasticnet', 'l1_ratio': 0.6351221010640696, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.8324682639918153.\n",
      "[I 2024-11-14 00:45:02,714] Trial 1 finished with value: 0.8328541605189675 and parameters: {'C': 71.77141927992021, 'penalty': 'elasticnet', 'l1_ratio': 0.024810409748678097, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 1 with value: 0.8328541605189675.\n",
      "[I 2024-11-14 00:45:03,249] Trial 2 finished with value: 0.8149494612197428 and parameters: {'C': 0.0017707168643537846, 'penalty': 'elasticnet', 'l1_ratio': 0.0004207053950287938, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 1 with value: 0.8328541605189675.\n",
      "2024-11-14 00:45:03,265 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/LogisticRegression_RandomSampler_marginal_45062.csv\n",
      "2024-11-14 00:45:03,268 - __main__ - INFO - Searching hyperparameter space with RandomSampler for LogisticRegression\n",
      "2024-11-14 00:45:03,273 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 43980\n",
      "[I 2024-11-14 00:45:03,275] A new study created in memory with name: no-name-3955f03c-ffe5-4a55-b750-8d9c7d4b781a\n",
      "[I 2024-11-14 00:45:03,279] A new study created in memory with name: no-name-c4576b70-72e4-40f7-9ce5-1c51a14fcda0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.8328541605189675], datetime_start=datetime.datetime(2024, 11, 14, 0, 44, 56, 487180), datetime_complete=datetime.datetime(2024, 11, 14, 0, 45, 2, 714344), params={'C': 71.77141927992021, 'penalty': 'elasticnet', 'l1_ratio': 0.024810409748678097, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'C': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'penalty': CategoricalDistribution(choices=('elasticnet',)), 'l1_ratio': FloatDistribution(high=1.0, log=True, low=0.0001, step=None), 'class_weight': CategoricalDistribution(choices=('balanced',)), 'max_iter': IntDistribution(high=1500, log=False, low=1500, step=1), 'solver': CategoricalDistribution(choices=('saga',))}, trial_id=1, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:45:03,476] Trial 0 finished with value: 0.8098475706459055 and parameters: {'C': 0.09915644566638401, 'penalty': 'elasticnet', 'l1_ratio': 0.6351221010640696, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.8098475706459055.\n",
      "[I 2024-11-14 00:45:03,708] Trial 1 finished with value: 0.8119067666282198 and parameters: {'C': 71.77141927992021, 'penalty': 'elasticnet', 'l1_ratio': 0.024810409748678097, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 1 with value: 0.8119067666282198.\n",
      "[I 2024-11-14 00:45:03,759] Trial 2 finished with value: 0.79272336361015 and parameters: {'C': 0.0017707168643537846, 'penalty': 'elasticnet', 'l1_ratio': 0.0004207053950287938, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 1 with value: 0.8119067666282198.\n",
      "2024-11-14 00:45:03,767 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/LogisticRegression_RandomSampler_marginal_43980.csv\n",
      "2024-11-14 00:45:03,769 - __main__ - INFO - Searching hyperparameter space with RandomSampler for ExtraTreesClassifier\n",
      "2024-11-14 00:45:03,769 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 31\n",
      "[I 2024-11-14 00:45:03,770] A new study created in memory with name: no-name-697c4136-2c85-4960-98e2-bd2aa463fd02\n",
      "[I 2024-11-14 00:45:03,770] A new study created in memory with name: no-name-f09096a3-6250-49de-97ed-07e1cb727cb4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.8119067666282198], datetime_start=datetime.datetime(2024, 11, 14, 0, 45, 3, 476723), datetime_complete=datetime.datetime(2024, 11, 14, 0, 45, 3, 708100), params={'C': 71.77141927992021, 'penalty': 'elasticnet', 'l1_ratio': 0.024810409748678097, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'C': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'penalty': CategoricalDistribution(choices=('elasticnet',)), 'l1_ratio': FloatDistribution(high=1.0, log=True, low=0.0001, step=None), 'class_weight': CategoricalDistribution(choices=('balanced',)), 'max_iter': IntDistribution(high=1500, log=False, low=1500, step=1), 'solver': CategoricalDistribution(choices=('saga',))}, trial_id=1, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:45:06,548] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 574, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.24041677639819287, 'max_features': 0.2403950683025824, 'min_samples_leaf': 0.15227525095137953}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:45:13,457] Trial 1 finished with value: 0.5674047619047619 and parameters: {'n_estimators': 1302, 'criterion': 'entropy', 'bootstrap': True, 'max_samples': 0.9729188669457949, 'max_features': 0.8491983767203796, 'min_samples_leaf': 0.29110519961044856}. Best is trial 1 with value: 0.5674047619047619.\n",
      "[I 2024-11-14 00:45:14,651] Trial 2 finished with value: 0.5 and parameters: {'n_estimators': 289, 'criterion': 'log_loss', 'bootstrap': True, 'max_samples': 0.48875051677790415, 'max_features': 0.36210622617823773, 'min_samples_leaf': 0.6506676052501416}. Best is trial 1 with value: 0.5674047619047619.\n",
      "2024-11-14 00:45:14,658 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/ExtraTreesClassifier_RandomSampler_marginal_31.csv\n",
      "2024-11-14 00:45:14,659 - __main__ - INFO - Searching hyperparameter space with RandomSampler for ExtraTreesClassifier\n",
      "2024-11-14 00:45:14,659 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 37\n",
      "[I 2024-11-14 00:45:14,659] A new study created in memory with name: no-name-73be13ae-1a45-494f-94c3-6f159d5b9c51\n",
      "[I 2024-11-14 00:45:14,660] A new study created in memory with name: no-name-cb9dfc6a-9e42-4144-89e7-e13e3fae64da\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.5674047619047619], datetime_start=datetime.datetime(2024, 11, 14, 0, 45, 6, 549871), datetime_complete=datetime.datetime(2024, 11, 14, 0, 45, 13, 457167), params={'n_estimators': 1302, 'criterion': 'entropy', 'bootstrap': True, 'max_samples': 0.9729188669457949, 'max_features': 0.8491983767203796, 'min_samples_leaf': 0.29110519961044856}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=1500, log=False, low=20, step=1), 'criterion': CategoricalDistribution(choices=('gini', 'entropy', 'log_loss')), 'bootstrap': CategoricalDistribution(choices=(True,)), 'max_samples': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'max_features': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'min_samples_leaf': FloatDistribution(high=1.0, log=False, low=0.1, step=None)}, trial_id=1, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:45:19,171] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 574, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.24041677639819287, 'max_features': 0.2403950683025824, 'min_samples_leaf': 0.15227525095137953}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:45:29,816] Trial 1 finished with value: 0.7775559049615653 and parameters: {'n_estimators': 1302, 'criterion': 'entropy', 'bootstrap': True, 'max_samples': 0.9729188669457949, 'max_features': 0.8491983767203796, 'min_samples_leaf': 0.29110519961044856}. Best is trial 1 with value: 0.7775559049615653.\n",
      "[I 2024-11-14 00:45:30,997] Trial 2 finished with value: 0.5 and parameters: {'n_estimators': 289, 'criterion': 'log_loss', 'bootstrap': True, 'max_samples': 0.48875051677790415, 'max_features': 0.36210622617823773, 'min_samples_leaf': 0.6506676052501416}. Best is trial 1 with value: 0.7775559049615653.\n",
      "2024-11-14 00:45:31,008 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/ExtraTreesClassifier_RandomSampler_marginal_37.csv\n",
      "2024-11-14 00:45:31,009 - __main__ - INFO - Searching hyperparameter space with RandomSampler for ExtraTreesClassifier\n",
      "2024-11-14 00:45:31,010 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 45062\n",
      "[I 2024-11-14 00:45:31,010] A new study created in memory with name: no-name-82956e77-e7c0-4efc-a139-547db0c83043\n",
      "[I 2024-11-14 00:45:31,011] A new study created in memory with name: no-name-ed0547d4-4fe6-43ad-91fa-5ebe9eb020a7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.7775559049615653], datetime_start=datetime.datetime(2024, 11, 14, 0, 45, 19, 172624), datetime_complete=datetime.datetime(2024, 11, 14, 0, 45, 29, 816549), params={'n_estimators': 1302, 'criterion': 'entropy', 'bootstrap': True, 'max_samples': 0.9729188669457949, 'max_features': 0.8491983767203796, 'min_samples_leaf': 0.29110519961044856}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=1500, log=False, low=20, step=1), 'criterion': CategoricalDistribution(choices=('gini', 'entropy', 'log_loss')), 'bootstrap': CategoricalDistribution(choices=(True,)), 'max_samples': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'max_features': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'min_samples_leaf': FloatDistribution(high=1.0, log=False, low=0.1, step=None)}, trial_id=1, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:45:34,350] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 574, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.24041677639819287, 'max_features': 0.2403950683025824, 'min_samples_leaf': 0.15227525095137953}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:45:45,293] Trial 1 finished with value: 0.72794513790491 and parameters: {'n_estimators': 1302, 'criterion': 'entropy', 'bootstrap': True, 'max_samples': 0.9729188669457949, 'max_features': 0.8491983767203796, 'min_samples_leaf': 0.29110519961044856}. Best is trial 1 with value: 0.72794513790491.\n",
      "[I 2024-11-14 00:45:49,378] Trial 2 finished with value: 0.5 and parameters: {'n_estimators': 289, 'criterion': 'log_loss', 'bootstrap': True, 'max_samples': 0.48875051677790415, 'max_features': 0.36210622617823773, 'min_samples_leaf': 0.6506676052501416}. Best is trial 1 with value: 0.72794513790491.\n",
      "2024-11-14 00:45:49,390 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/ExtraTreesClassifier_RandomSampler_marginal_45062.csv\n",
      "2024-11-14 00:45:49,393 - __main__ - INFO - Searching hyperparameter space with RandomSampler for ExtraTreesClassifier\n",
      "2024-11-14 00:45:49,393 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 43980\n",
      "[I 2024-11-14 00:45:49,394] A new study created in memory with name: no-name-7863ecb7-d743-4cfb-bca2-29a862631dbf\n",
      "[I 2024-11-14 00:45:49,396] A new study created in memory with name: no-name-31084223-409a-47dd-8f4a-54c66d0b48d3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.72794513790491], datetime_start=datetime.datetime(2024, 11, 14, 0, 45, 34, 350784), datetime_complete=datetime.datetime(2024, 11, 14, 0, 45, 45, 293272), params={'n_estimators': 1302, 'criterion': 'entropy', 'bootstrap': True, 'max_samples': 0.9729188669457949, 'max_features': 0.8491983767203796, 'min_samples_leaf': 0.29110519961044856}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=1500, log=False, low=20, step=1), 'criterion': CategoricalDistribution(choices=('gini', 'entropy', 'log_loss')), 'bootstrap': CategoricalDistribution(choices=(True,)), 'max_samples': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'max_features': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'min_samples_leaf': FloatDistribution(high=1.0, log=False, low=0.1, step=None)}, trial_id=1, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:45:55,218] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 574, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.24041677639819287, 'max_features': 0.2403950683025824, 'min_samples_leaf': 0.15227525095137953}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:46:05,194] Trial 1 finished with value: 0.7558317353902345 and parameters: {'n_estimators': 1302, 'criterion': 'entropy', 'bootstrap': True, 'max_samples': 0.9729188669457949, 'max_features': 0.8491983767203796, 'min_samples_leaf': 0.29110519961044856}. Best is trial 1 with value: 0.7558317353902345.\n",
      "[I 2024-11-14 00:46:06,414] Trial 2 finished with value: 0.5 and parameters: {'n_estimators': 289, 'criterion': 'log_loss', 'bootstrap': True, 'max_samples': 0.48875051677790415, 'max_features': 0.36210622617823773, 'min_samples_leaf': 0.6506676052501416}. Best is trial 1 with value: 0.7558317353902345.\n",
      "2024-11-14 00:46:06,420 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/ExtraTreesClassifier_RandomSampler_marginal_43980.csv\n",
      "2024-11-14 00:46:06,422 - __main__ - INFO - Searching hyperparameter space with RandomSampler for XGBClassifier\n",
      "2024-11-14 00:46:06,422 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 31\n",
      "[I 2024-11-14 00:46:06,423] A new study created in memory with name: no-name-c945889c-7d01-4bb8-983c-074accb119c7\n",
      "[I 2024-11-14 00:46:06,424] A new study created in memory with name: no-name-9658f384-410e-4b74-aa14-33dc7643e689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.7558317353902345], datetime_start=datetime.datetime(2024, 11, 14, 0, 45, 55, 218922), datetime_complete=datetime.datetime(2024, 11, 14, 0, 46, 5, 194364), params={'n_estimators': 1302, 'criterion': 'entropy', 'bootstrap': True, 'max_samples': 0.9729188669457949, 'max_features': 0.8491983767203796, 'min_samples_leaf': 0.29110519961044856}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=1500, log=False, low=20, step=1), 'criterion': CategoricalDistribution(choices=('gini', 'entropy', 'log_loss')), 'bootstrap': CategoricalDistribution(choices=(True,)), 'max_samples': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'max_features': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'min_samples_leaf': FloatDistribution(high=1.0, log=False, low=0.1, step=None)}, trial_id=1, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:46:08,157] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 1873, 'learning_rate': 0.1804941906677887, 'subsample': 0.7587945476302645, 'booster': 'gbtree', 'max_depth': 9, 'min_child_weight': 20.814367336189438, 'colsample_bytree': 0.16443457513284063, 'colsample_bylevel': 0.06750277604651747, 'reg_alpha': 849.9808989183019, 'reg_lambda': 6.4405075539937195}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:46:12,048] Trial 1 finished with value: 0.7754166666666666 and parameters: {'n_estimators': 3541, 'learning_rate': 1.236400798668794e-05, 'subsample': 0.9729188669457949, 'booster': 'gbtree', 'max_depth': 13, 'min_child_weight': 27.967067056141072, 'colsample_bytree': 0.19000671753502962, 'colsample_bylevel': 0.1915704647548995, 'reg_alpha': 0.027160511446548512, 'reg_lambda': 1.5777981883365035}. Best is trial 1 with value: 0.7754166666666666.\n",
      "[I 2024-11-14 00:46:14,088] Trial 2 finished with value: 0.5 and parameters: {'n_estimators': 2160, 'learning_rate': 0.0002013113093617531, 'subsample': 0.6506676052501416, 'booster': 'gbtree', 'max_depth': 3, 'min_child_weight': 38.1023703639727, 'colsample_bytree': 0.37269822486075477, 'colsample_bylevel': 0.46150928437486555, 'reg_alpha': 191.16469627784303, 'reg_lambda': 0.0039572205641009274}. Best is trial 1 with value: 0.7754166666666666.\n",
      "2024-11-14 00:46:14,095 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/XGBClassifier_RandomSampler_marginal_31.csv\n",
      "2024-11-14 00:46:14,096 - __main__ - INFO - Searching hyperparameter space with RandomSampler for XGBClassifier\n",
      "2024-11-14 00:46:14,097 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 37\n",
      "[I 2024-11-14 00:46:14,098] A new study created in memory with name: no-name-6c0182f7-7cd3-4f4e-8cab-19cecc417219\n",
      "[I 2024-11-14 00:46:14,099] A new study created in memory with name: no-name-0163df58-ece1-4853-9315-9df6ff3b49d5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.7754166666666666], datetime_start=datetime.datetime(2024, 11, 14, 0, 46, 8, 158124), datetime_complete=datetime.datetime(2024, 11, 14, 0, 46, 12, 48047), params={'n_estimators': 3541, 'learning_rate': 1.236400798668794e-05, 'subsample': 0.9729188669457949, 'booster': 'gbtree', 'max_depth': 13, 'min_child_weight': 27.967067056141072, 'colsample_bytree': 0.19000671753502962, 'colsample_bylevel': 0.1915704647548995, 'reg_alpha': 0.027160511446548512, 'reg_lambda': 1.5777981883365035}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=5000, log=False, low=1, step=1), 'learning_rate': FloatDistribution(high=0.3, log=True, low=1e-05, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'booster': CategoricalDistribution(choices=('gbtree',)), 'max_depth': IntDistribution(high=15, log=False, low=1, step=1), 'min_child_weight': FloatDistribution(high=128.0, log=False, low=1.0, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'colsample_bylevel': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'reg_alpha': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None)}, trial_id=1, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:46:15,226] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 1873, 'learning_rate': 0.1804941906677887, 'subsample': 0.7587945476302645, 'booster': 'gbtree', 'max_depth': 9, 'min_child_weight': 20.814367336189438, 'colsample_bytree': 0.16443457513284063, 'colsample_bylevel': 0.06750277604651747, 'reg_alpha': 849.9808989183019, 'reg_lambda': 6.4405075539937195}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:46:18,715] Trial 1 finished with value: 0.8073812019566737 and parameters: {'n_estimators': 3541, 'learning_rate': 1.236400798668794e-05, 'subsample': 0.9729188669457949, 'booster': 'gbtree', 'max_depth': 13, 'min_child_weight': 27.967067056141072, 'colsample_bytree': 0.19000671753502962, 'colsample_bylevel': 0.1915704647548995, 'reg_alpha': 0.027160511446548512, 'reg_lambda': 1.5777981883365035}. Best is trial 1 with value: 0.8073812019566737.\n",
      "[I 2024-11-14 00:46:20,064] Trial 2 finished with value: 0.5 and parameters: {'n_estimators': 2160, 'learning_rate': 0.0002013113093617531, 'subsample': 0.6506676052501416, 'booster': 'gbtree', 'max_depth': 3, 'min_child_weight': 38.1023703639727, 'colsample_bytree': 0.37269822486075477, 'colsample_bylevel': 0.46150928437486555, 'reg_alpha': 191.16469627784303, 'reg_lambda': 0.0039572205641009274}. Best is trial 1 with value: 0.8073812019566737.\n",
      "2024-11-14 00:46:20,070 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/XGBClassifier_RandomSampler_marginal_37.csv\n",
      "2024-11-14 00:46:20,071 - __main__ - INFO - Searching hyperparameter space with RandomSampler for XGBClassifier\n",
      "2024-11-14 00:46:20,072 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 45062\n",
      "[I 2024-11-14 00:46:20,072] A new study created in memory with name: no-name-50361ffb-ad50-48ad-abbe-6f5a123f0adb\n",
      "[I 2024-11-14 00:46:20,073] A new study created in memory with name: no-name-9750651e-15f6-45e7-bd5f-9ea86e18c59b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.8073812019566737], datetime_start=datetime.datetime(2024, 11, 14, 0, 46, 15, 226882), datetime_complete=datetime.datetime(2024, 11, 14, 0, 46, 18, 715133), params={'n_estimators': 3541, 'learning_rate': 1.236400798668794e-05, 'subsample': 0.9729188669457949, 'booster': 'gbtree', 'max_depth': 13, 'min_child_weight': 27.967067056141072, 'colsample_bytree': 0.19000671753502962, 'colsample_bylevel': 0.1915704647548995, 'reg_alpha': 0.027160511446548512, 'reg_lambda': 1.5777981883365035}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=5000, log=False, low=1, step=1), 'learning_rate': FloatDistribution(high=0.3, log=True, low=1e-05, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'booster': CategoricalDistribution(choices=('gbtree',)), 'max_depth': IntDistribution(high=15, log=False, low=1, step=1), 'min_child_weight': FloatDistribution(high=128.0, log=False, low=1.0, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'colsample_bylevel': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'reg_alpha': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None)}, trial_id=1, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:46:22,289] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 1873, 'learning_rate': 0.1804941906677887, 'subsample': 0.7587945476302645, 'booster': 'gbtree', 'max_depth': 9, 'min_child_weight': 20.814367336189438, 'colsample_bytree': 0.16443457513284063, 'colsample_bylevel': 0.06750277604651747, 'reg_alpha': 849.9808989183019, 'reg_lambda': 6.4405075539937195}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:46:32,690] Trial 1 finished with value: 0.8326656294414374 and parameters: {'n_estimators': 3541, 'learning_rate': 1.236400798668794e-05, 'subsample': 0.9729188669457949, 'booster': 'gbtree', 'max_depth': 13, 'min_child_weight': 27.967067056141072, 'colsample_bytree': 0.19000671753502962, 'colsample_bylevel': 0.1915704647548995, 'reg_alpha': 0.027160511446548512, 'reg_lambda': 1.5777981883365035}. Best is trial 1 with value: 0.8326656294414374.\n",
      "[I 2024-11-14 00:46:41,556] Trial 2 finished with value: 0.8132203549627315 and parameters: {'n_estimators': 2160, 'learning_rate': 0.0002013113093617531, 'subsample': 0.6506676052501416, 'booster': 'gbtree', 'max_depth': 3, 'min_child_weight': 38.1023703639727, 'colsample_bytree': 0.37269822486075477, 'colsample_bylevel': 0.46150928437486555, 'reg_alpha': 191.16469627784303, 'reg_lambda': 0.0039572205641009274}. Best is trial 1 with value: 0.8326656294414374.\n",
      "2024-11-14 00:46:41,563 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/XGBClassifier_RandomSampler_marginal_45062.csv\n",
      "2024-11-14 00:46:41,565 - __main__ - INFO - Searching hyperparameter space with RandomSampler for XGBClassifier\n",
      "2024-11-14 00:46:41,565 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 43980\n",
      "[I 2024-11-14 00:46:41,566] A new study created in memory with name: no-name-d0b05e51-b4be-4d72-9d5a-81a171c14ce4\n",
      "[I 2024-11-14 00:46:41,566] A new study created in memory with name: no-name-4d8071a7-a2c3-4c9e-b0fd-ed30d9abb905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.8326656294414374], datetime_start=datetime.datetime(2024, 11, 14, 0, 46, 22, 290406), datetime_complete=datetime.datetime(2024, 11, 14, 0, 46, 32, 689690), params={'n_estimators': 3541, 'learning_rate': 1.236400798668794e-05, 'subsample': 0.9729188669457949, 'booster': 'gbtree', 'max_depth': 13, 'min_child_weight': 27.967067056141072, 'colsample_bytree': 0.19000671753502962, 'colsample_bylevel': 0.1915704647548995, 'reg_alpha': 0.027160511446548512, 'reg_lambda': 1.5777981883365035}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=5000, log=False, low=1, step=1), 'learning_rate': FloatDistribution(high=0.3, log=True, low=1e-05, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'booster': CategoricalDistribution(choices=('gbtree',)), 'max_depth': IntDistribution(high=15, log=False, low=1, step=1), 'min_child_weight': FloatDistribution(high=128.0, log=False, low=1.0, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'colsample_bylevel': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'reg_alpha': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None)}, trial_id=1, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:46:43,039] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 1873, 'learning_rate': 0.1804941906677887, 'subsample': 0.7587945476302645, 'booster': 'gbtree', 'max_depth': 9, 'min_child_weight': 20.814367336189438, 'colsample_bytree': 0.16443457513284063, 'colsample_bylevel': 0.06750277604651747, 'reg_alpha': 849.9808989183019, 'reg_lambda': 6.4405075539937195}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:46:57,952] Trial 1 finished with value: 0.8181128652441367 and parameters: {'n_estimators': 3541, 'learning_rate': 1.236400798668794e-05, 'subsample': 0.9729188669457949, 'booster': 'gbtree', 'max_depth': 13, 'min_child_weight': 27.967067056141072, 'colsample_bytree': 0.19000671753502962, 'colsample_bylevel': 0.1915704647548995, 'reg_alpha': 0.027160511446548512, 'reg_lambda': 1.5777981883365035}. Best is trial 1 with value: 0.8181128652441367.\n",
      "[I 2024-11-14 00:47:02,019] Trial 2 finished with value: 0.5 and parameters: {'n_estimators': 2160, 'learning_rate': 0.0002013113093617531, 'subsample': 0.6506676052501416, 'booster': 'gbtree', 'max_depth': 3, 'min_child_weight': 38.1023703639727, 'colsample_bytree': 0.37269822486075477, 'colsample_bylevel': 0.46150928437486555, 'reg_alpha': 191.16469627784303, 'reg_lambda': 0.0039572205641009274}. Best is trial 1 with value: 0.8181128652441367.\n",
      "2024-11-14 00:47:02,030 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/XGBClassifier_RandomSampler_marginal_43980.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.8181128652441367], datetime_start=datetime.datetime(2024, 11, 14, 0, 46, 43, 40177), datetime_complete=datetime.datetime(2024, 11, 14, 0, 46, 57, 952112), params={'n_estimators': 3541, 'learning_rate': 1.236400798668794e-05, 'subsample': 0.9729188669457949, 'booster': 'gbtree', 'max_depth': 13, 'min_child_weight': 27.967067056141072, 'colsample_bytree': 0.19000671753502962, 'colsample_bylevel': 0.1915704647548995, 'reg_alpha': 0.027160511446548512, 'reg_lambda': 1.5777981883365035}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=5000, log=False, low=1, step=1), 'learning_rate': FloatDistribution(high=0.3, log=True, low=1e-05, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'booster': CategoricalDistribution(choices=('gbtree',)), 'max_depth': IntDistribution(high=15, log=False, low=1, step=1), 'min_child_weight': FloatDistribution(high=128.0, log=False, low=1.0, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'colsample_bylevel': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'reg_alpha': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None)}, trial_id=1, value=None)]\n",
      "Best params for lr:\n",
      "  Dataset 31:\n",
      "    C: 71.77141927992021\n",
      "    penalty: elasticnet\n",
      "    l1_ratio: 0.024810409748678097\n",
      "    class_weight: balanced\n",
      "    max_iter: 1500\n",
      "    solver: saga\n",
      "  Dataset 37:\n",
      "    C: 0.09915644566638401\n",
      "    penalty: elasticnet\n",
      "    l1_ratio: 0.6351221010640696\n",
      "    class_weight: balanced\n",
      "    max_iter: 1500\n",
      "    solver: saga\n",
      "  Dataset 45062:\n",
      "    C: 71.77141927992021\n",
      "    penalty: elasticnet\n",
      "    l1_ratio: 0.024810409748678097\n",
      "    class_weight: balanced\n",
      "    max_iter: 1500\n",
      "    solver: saga\n",
      "  Dataset 43980:\n",
      "    C: 71.77141927992021\n",
      "    penalty: elasticnet\n",
      "    l1_ratio: 0.024810409748678097\n",
      "    class_weight: balanced\n",
      "    max_iter: 1500\n",
      "    solver: saga\n",
      "\n",
      "\n",
      "Best params for et:\n",
      "  Dataset 31:\n",
      "    n_estimators: 1302\n",
      "    criterion: entropy\n",
      "    bootstrap: True\n",
      "    max_samples: 0.9729188669457949\n",
      "    max_features: 0.8491983767203796\n",
      "    min_samples_leaf: 0.29110519961044856\n",
      "  Dataset 37:\n",
      "    n_estimators: 1302\n",
      "    criterion: entropy\n",
      "    bootstrap: True\n",
      "    max_samples: 0.9729188669457949\n",
      "    max_features: 0.8491983767203796\n",
      "    min_samples_leaf: 0.29110519961044856\n",
      "  Dataset 45062:\n",
      "    n_estimators: 1302\n",
      "    criterion: entropy\n",
      "    bootstrap: True\n",
      "    max_samples: 0.9729188669457949\n",
      "    max_features: 0.8491983767203796\n",
      "    min_samples_leaf: 0.29110519961044856\n",
      "  Dataset 43980:\n",
      "    n_estimators: 1302\n",
      "    criterion: entropy\n",
      "    bootstrap: True\n",
      "    max_samples: 0.9729188669457949\n",
      "    max_features: 0.8491983767203796\n",
      "    min_samples_leaf: 0.29110519961044856\n",
      "\n",
      "\n",
      "Best params for xgb:\n",
      "  Dataset 31:\n",
      "    n_estimators: 3541\n",
      "    learning_rate: 1.236400798668794e-05\n",
      "    subsample: 0.9729188669457949\n",
      "    booster: gbtree\n",
      "    max_depth: 13\n",
      "    min_child_weight: 27.967067056141072\n",
      "    colsample_bytree: 0.19000671753502962\n",
      "    colsample_bylevel: 0.1915704647548995\n",
      "    reg_alpha: 0.027160511446548512\n",
      "    reg_lambda: 1.5777981883365035\n",
      "  Dataset 37:\n",
      "    n_estimators: 3541\n",
      "    learning_rate: 1.236400798668794e-05\n",
      "    subsample: 0.9729188669457949\n",
      "    booster: gbtree\n",
      "    max_depth: 13\n",
      "    min_child_weight: 27.967067056141072\n",
      "    colsample_bytree: 0.19000671753502962\n",
      "    colsample_bylevel: 0.1915704647548995\n",
      "    reg_alpha: 0.027160511446548512\n",
      "    reg_lambda: 1.5777981883365035\n",
      "  Dataset 45062:\n",
      "    n_estimators: 3541\n",
      "    learning_rate: 1.236400798668794e-05\n",
      "    subsample: 0.9729188669457949\n",
      "    booster: gbtree\n",
      "    max_depth: 13\n",
      "    min_child_weight: 27.967067056141072\n",
      "    colsample_bytree: 0.19000671753502962\n",
      "    colsample_bylevel: 0.1915704647548995\n",
      "    reg_alpha: 0.027160511446548512\n",
      "    reg_lambda: 1.5777981883365035\n",
      "  Dataset 43980:\n",
      "    n_estimators: 3541\n",
      "    learning_rate: 1.236400798668794e-05\n",
      "    subsample: 0.9729188669457949\n",
      "    booster: gbtree\n",
      "    max_depth: 13\n",
      "    min_child_weight: 27.967067056141072\n",
      "    colsample_bytree: 0.19000671753502962\n",
      "    colsample_bylevel: 0.1915704647548995\n",
      "    reg_alpha: 0.027160511446548512\n",
      "    reg_lambda: 1.5777981883365035\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampler = SAMPLERS[0]\n",
    "best_params_dict = {}\n",
    "\n",
    "for model, param_grid in MODELS:\n",
    "    for ID, X, y in zip(DATASET_IDS, Xs, ys):\n",
    "        trials, study = run_experiment_marginal(model, sampler, X, y, ID, param_grid, results_dir, n_trials=300)\n",
    "        model_name = {'LogisticRegression': 'lr', 'ExtraTreesClassifier': 'et', 'XGBClassifier': 'xgb'}[model.__name__]\n",
    "        save_study_to_pickle_marginal(study, model_name, 'RS', ID)\n",
    "        best_params = study.best_trials[0].params\n",
    "    \n",
    "        if model_name not in best_params_dict:\n",
    "            best_params_dict[model_name] = {}\n",
    "        best_params_dict[model_name][ID] = best_params\n",
    "        \n",
    "with open(os.path.join(results_bestparams_dir, 'best_params_dict_RS.json'), 'w') as f:\n",
    "    json.dump(best_params_dict, f)\n",
    "\n",
    "for model_name, datasets in best_params_dict.items():\n",
    "    print(f\"Best params for {model_name}:\")\n",
    "    for ID, params in datasets.items():\n",
    "        print(f\"  Dataset {ID}:\")\n",
    "        for param_name, value in params.items():\n",
    "            print(f\"    {param_name}: {value}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization with TPE (Bayes Search) for Logistic Regression, Extra Trees and XGBoost at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T23:48:02.126389Z",
     "start_time": "2024-11-13T23:47:02.098261Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-14 00:47:02,101 - __main__ - INFO - Searching hyperparameter space with TPESampler for LogisticRegression\n",
      "2024-11-14 00:47:02,103 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 31\n",
      "[I 2024-11-14 00:47:02,104] A new study created in memory with name: no-name-59c9fc45-b61a-452e-8230-6c695a0a82b4\n",
      "[I 2024-11-14 00:47:02,105] A new study created in memory with name: no-name-1143f6a7-6944-4743-81d4-54a08aa516e6\n",
      "[I 2024-11-14 00:47:02,321] Trial 0 finished with value: 0.7788095238095238 and parameters: {'C': 0.09915644566638401, 'penalty': 'elasticnet', 'l1_ratio': 0.6351221010640696, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.7788095238095238.\n",
      "[I 2024-11-14 00:47:02,324] A new study created in memory with name: no-name-ec68c371-85a2-4a4a-9ab0-4b2ae6a39ed0\n",
      "[I 2024-11-14 00:47:02,493] Trial 0 finished with value: 0.7777619047619047 and parameters: {'C': 0.023441926146948493, 'penalty': 'elasticnet', 'l1_ratio': 0.17229428125126015, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.7777619047619047.\n",
      "[I 2024-11-14 00:47:02,495] A new study created in memory with name: no-name-26b33994-c2e7-46d4-9144-b6b5afd1d494\n",
      "[I 2024-11-14 00:47:02,687] Trial 0 finished with value: 0.7863333333333332 and parameters: {'C': 0.03350945131274967, 'penalty': 'elasticnet', 'l1_ratio': 0.00648817727333381, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.7863333333333332.\n",
      "2024-11-14 00:47:02,698 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/LogisticRegression_TPESampler_marginal_31.csv\n",
      "2024-11-14 00:47:02,700 - __main__ - INFO - Searching hyperparameter space with TPESampler for LogisticRegression\n",
      "2024-11-14 00:47:02,701 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 37\n",
      "[I 2024-11-14 00:47:02,702] A new study created in memory with name: no-name-7cdc2c27-c93c-4a6b-ad90-13f7f74e9b0b\n",
      "[I 2024-11-14 00:47:02,703] A new study created in memory with name: no-name-088f5aec-64ac-4482-a4b6-f9e3e93899d8\n",
      "[I 2024-11-14 00:47:02,755] Trial 0 finished with value: 0.8299965059399023 and parameters: {'C': 0.09915644566638401, 'penalty': 'elasticnet', 'l1_ratio': 0.6351221010640696, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.8299965059399023.\n",
      "[I 2024-11-14 00:47:02,757] A new study created in memory with name: no-name-784a3f14-ca98-4bed-a1d8-dbff0111c9f6\n",
      "[I 2024-11-14 00:47:02,809] Trial 0 finished with value: 0.8286883298392732 and parameters: {'C': 0.023441926146948493, 'penalty': 'elasticnet', 'l1_ratio': 0.17229428125126015, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.8286883298392732.\n",
      "[I 2024-11-14 00:47:02,811] A new study created in memory with name: no-name-25ab078f-6e76-4e30-89f2-f5f31ff4b871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=2, state=1, values=[0.7863333333333332], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 2, 496471), datetime_complete=datetime.datetime(2024, 11, 14, 0, 47, 2, 687447), params={'C': 0.03350945131274967, 'penalty': 'elasticnet', 'l1_ratio': 0.00648817727333381, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'C': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'penalty': CategoricalDistribution(choices=('elasticnet',)), 'l1_ratio': FloatDistribution(high=1.0, log=True, low=0.0001, step=None), 'class_weight': CategoricalDistribution(choices=('balanced',)), 'max_iter': IntDistribution(high=1500, log=False, low=1500, step=1), 'solver': CategoricalDistribution(choices=('saga',))}, trial_id=2, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:47:02,954] Trial 0 finished with value: 0.828962962962963 and parameters: {'C': 0.03350945131274967, 'penalty': 'elasticnet', 'l1_ratio': 0.00648817727333381, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.828962962962963.\n",
      "2024-11-14 00:47:02,964 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/LogisticRegression_TPESampler_marginal_37.csv\n",
      "2024-11-14 00:47:02,966 - __main__ - INFO - Searching hyperparameter space with TPESampler for LogisticRegression\n",
      "2024-11-14 00:47:02,967 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 45062\n",
      "[I 2024-11-14 00:47:02,967] A new study created in memory with name: no-name-fd2f3ebb-7c89-47ac-bce1-b7123fd8f9d6\n",
      "[I 2024-11-14 00:47:02,969] A new study created in memory with name: no-name-77aa0bd0-2b13-416b-b190-e2f9a51fca2b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=0, state=1, values=[0.8299965059399023], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 2, 704345), datetime_complete=datetime.datetime(2024, 11, 14, 0, 47, 2, 755340), params={'C': 0.09915644566638401, 'penalty': 'elasticnet', 'l1_ratio': 0.6351221010640696, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'C': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'penalty': CategoricalDistribution(choices=('elasticnet',)), 'l1_ratio': FloatDistribution(high=1.0, log=True, low=0.0001, step=None), 'class_weight': CategoricalDistribution(choices=('balanced',)), 'max_iter': IntDistribution(high=1500, log=False, low=1500, step=1), 'solver': CategoricalDistribution(choices=('saga',))}, trial_id=0, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:47:03,496] Trial 0 finished with value: 0.8324682617407145 and parameters: {'C': 0.09915644566638401, 'penalty': 'elasticnet', 'l1_ratio': 0.6351221010640696, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.8324682617407145.\n",
      "[I 2024-11-14 00:47:03,498] A new study created in memory with name: no-name-79483db6-d218-4bd7-af03-d97d7a9c0314\n",
      "[I 2024-11-14 00:47:04,059] Trial 0 finished with value: 0.8298975908720951 and parameters: {'C': 0.023441926146948493, 'penalty': 'elasticnet', 'l1_ratio': 0.17229428125126015, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.8298975908720951.\n",
      "[I 2024-11-14 00:47:04,061] A new study created in memory with name: no-name-1c818204-96ea-4723-b3f5-e1a791a3d099\n",
      "[I 2024-11-14 00:47:04,679] Trial 0 finished with value: 0.8304099249588317 and parameters: {'C': 0.03350945131274967, 'penalty': 'elasticnet', 'l1_ratio': 0.00648817727333381, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.8304099249588317.\n",
      "2024-11-14 00:47:04,694 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/LogisticRegression_TPESampler_marginal_45062.csv\n",
      "2024-11-14 00:47:04,698 - __main__ - INFO - Searching hyperparameter space with TPESampler for LogisticRegression\n",
      "2024-11-14 00:47:04,700 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 43980\n",
      "[I 2024-11-14 00:47:04,703] A new study created in memory with name: no-name-63062802-2593-4dc8-9bd9-22efad01a1fa\n",
      "[I 2024-11-14 00:47:04,706] A new study created in memory with name: no-name-a795c86b-1cea-4231-b0db-92abcf4e363b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=0, state=1, values=[0.8324682617407145], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 2, 969713), datetime_complete=datetime.datetime(2024, 11, 14, 0, 47, 3, 496142), params={'C': 0.09915644566638401, 'penalty': 'elasticnet', 'l1_ratio': 0.6351221010640696, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'C': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'penalty': CategoricalDistribution(choices=('elasticnet',)), 'l1_ratio': FloatDistribution(high=1.0, log=True, low=0.0001, step=None), 'class_weight': CategoricalDistribution(choices=('balanced',)), 'max_iter': IntDistribution(high=1500, log=False, low=1500, step=1), 'solver': CategoricalDistribution(choices=('saga',))}, trial_id=0, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:47:04,918] Trial 0 finished with value: 0.8098475706459055 and parameters: {'C': 0.09915644566638401, 'penalty': 'elasticnet', 'l1_ratio': 0.6351221010640696, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.8098475706459055.\n",
      "[I 2024-11-14 00:47:04,921] A new study created in memory with name: no-name-3f4d93be-a79d-4cff-8374-e3b0485f58a9\n",
      "[I 2024-11-14 00:47:05,020] Trial 0 finished with value: 0.8089955545943868 and parameters: {'C': 0.023441926146948493, 'penalty': 'elasticnet', 'l1_ratio': 0.17229428125126015, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.8089955545943868.\n",
      "[I 2024-11-14 00:47:05,022] A new study created in memory with name: no-name-bfc8fa54-ee8e-4089-a1d9-340819d0ab2b\n",
      "[I 2024-11-14 00:47:05,126] Trial 0 finished with value: 0.8109811731064974 and parameters: {'C': 0.03350945131274967, 'penalty': 'elasticnet', 'l1_ratio': 0.00648817727333381, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}. Best is trial 0 with value: 0.8109811731064974.\n",
      "2024-11-14 00:47:05,135 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/LogisticRegression_TPESampler_marginal_43980.csv\n",
      "2024-11-14 00:47:05,137 - __main__ - INFO - Searching hyperparameter space with TPESampler for ExtraTreesClassifier\n",
      "2024-11-14 00:47:05,137 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 31\n",
      "[I 2024-11-14 00:47:05,138] A new study created in memory with name: no-name-678144c7-6251-4498-98ea-8d86e7af3d2f\n",
      "[I 2024-11-14 00:47:05,139] A new study created in memory with name: no-name-42c3a4e2-699a-42f4-8eaf-8a09e20dd119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=2, state=1, values=[0.8109811731064974], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 5, 23256), datetime_complete=datetime.datetime(2024, 11, 14, 0, 47, 5, 126211), params={'C': 0.03350945131274967, 'penalty': 'elasticnet', 'l1_ratio': 0.00648817727333381, 'class_weight': 'balanced', 'max_iter': 1500, 'solver': 'saga'}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'C': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'penalty': CategoricalDistribution(choices=('elasticnet',)), 'l1_ratio': FloatDistribution(high=1.0, log=True, low=0.0001, step=None), 'class_weight': CategoricalDistribution(choices=('balanced',)), 'max_iter': IntDistribution(high=1500, log=False, low=1500, step=1), 'solver': CategoricalDistribution(choices=('saga',))}, trial_id=2, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:47:08,359] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 574, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.24041677639819287, 'max_features': 0.2403950683025824, 'min_samples_leaf': 0.15227525095137953}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:47:08,360] A new study created in memory with name: no-name-ad8708a9-e54b-4592-9946-3b2e29f16e02\n",
      "[I 2024-11-14 00:47:10,657] Trial 0 finished with value: 0.6250595238095238 and parameters: {'n_estimators': 458, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.6052140781935152, 'max_features': 0.32823005879811984, 'min_samples_leaf': 0.19447937531659815}. Best is trial 0 with value: 0.6250595238095238.\n",
      "[I 2024-11-14 00:47:10,658] A new study created in memory with name: no-name-befb184e-6f69-4fcc-b810-23ffc7121e57\n",
      "[I 2024-11-14 00:47:12,883] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 487, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.8813498313568406, 'max_features': 0.6667556660442842, 'min_samples_leaf': 0.41726683712558366}. Best is trial 0 with value: 0.5.\n",
      "2024-11-14 00:47:12,890 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/ExtraTreesClassifier_TPESampler_marginal_31.csv\n",
      "2024-11-14 00:47:12,891 - __main__ - INFO - Searching hyperparameter space with TPESampler for ExtraTreesClassifier\n",
      "2024-11-14 00:47:12,892 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 37\n",
      "[I 2024-11-14 00:47:12,892] A new study created in memory with name: no-name-d999c7fc-4729-4e68-98f0-29e07c27193d\n",
      "[I 2024-11-14 00:47:12,893] A new study created in memory with name: no-name-bcc2dfd1-bfea-4a61-b634-97890973f9ca\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.6250595238095238], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 8, 361086), datetime_complete=datetime.datetime(2024, 11, 14, 0, 47, 10, 657472), params={'n_estimators': 458, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.6052140781935152, 'max_features': 0.32823005879811984, 'min_samples_leaf': 0.19447937531659815}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=1500, log=False, low=20, step=1), 'criterion': CategoricalDistribution(choices=('gini', 'entropy', 'log_loss')), 'bootstrap': CategoricalDistribution(choices=(True,)), 'max_samples': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'max_features': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'min_samples_leaf': FloatDistribution(high=1.0, log=False, low=0.1, step=None)}, trial_id=1, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:47:15,534] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 574, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.24041677639819287, 'max_features': 0.2403950683025824, 'min_samples_leaf': 0.15227525095137953}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:47:15,535] A new study created in memory with name: no-name-6f6e72b7-56f9-4351-b386-5c7c519be8c2\n",
      "[I 2024-11-14 00:47:17,598] Trial 0 finished with value: 0.7757739343116701 and parameters: {'n_estimators': 458, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.6052140781935152, 'max_features': 0.32823005879811984, 'min_samples_leaf': 0.19447937531659815}. Best is trial 0 with value: 0.7757739343116701.\n",
      "[I 2024-11-14 00:47:17,599] A new study created in memory with name: no-name-1f62eaa5-f39e-40f9-b35f-87267be4bb4e\n",
      "[I 2024-11-14 00:47:20,066] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 487, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.8813498313568406, 'max_features': 0.6667556660442842, 'min_samples_leaf': 0.41726683712558366}. Best is trial 0 with value: 0.5.\n",
      "2024-11-14 00:47:20,077 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/ExtraTreesClassifier_TPESampler_marginal_37.csv\n",
      "2024-11-14 00:47:20,078 - __main__ - INFO - Searching hyperparameter space with TPESampler for ExtraTreesClassifier\n",
      "2024-11-14 00:47:20,079 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 45062\n",
      "[I 2024-11-14 00:47:20,079] A new study created in memory with name: no-name-dfce36a7-a189-4bc4-82a9-cc23775acafe\n",
      "[I 2024-11-14 00:47:20,080] A new study created in memory with name: no-name-24c45ecd-7284-48d3-965d-6ebc43299f0d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.7757739343116701], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 15, 535802), datetime_complete=datetime.datetime(2024, 11, 14, 0, 47, 17, 597811), params={'n_estimators': 458, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.6052140781935152, 'max_features': 0.32823005879811984, 'min_samples_leaf': 0.19447937531659815}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=1500, log=False, low=20, step=1), 'criterion': CategoricalDistribution(choices=('gini', 'entropy', 'log_loss')), 'bootstrap': CategoricalDistribution(choices=(True,)), 'max_samples': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'max_features': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'min_samples_leaf': FloatDistribution(high=1.0, log=False, low=0.1, step=None)}, trial_id=1, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:47:24,149] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 574, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.24041677639819287, 'max_features': 0.2403950683025824, 'min_samples_leaf': 0.15227525095137953}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:47:24,150] A new study created in memory with name: no-name-0e15d777-5405-4366-a4b7-48eae7054e92\n",
      "[I 2024-11-14 00:47:27,845] Trial 0 finished with value: 0.7654046251238892 and parameters: {'n_estimators': 458, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.6052140781935152, 'max_features': 0.32823005879811984, 'min_samples_leaf': 0.19447937531659815}. Best is trial 0 with value: 0.7654046251238892.\n",
      "[I 2024-11-14 00:47:27,846] A new study created in memory with name: no-name-d8ebc775-10dc-48d7-82ab-8bff3030f9f9\n",
      "[I 2024-11-14 00:47:31,537] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 487, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.8813498313568406, 'max_features': 0.6667556660442842, 'min_samples_leaf': 0.41726683712558366}. Best is trial 0 with value: 0.5.\n",
      "2024-11-14 00:47:31,544 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/ExtraTreesClassifier_TPESampler_marginal_45062.csv\n",
      "2024-11-14 00:47:31,546 - __main__ - INFO - Searching hyperparameter space with TPESampler for ExtraTreesClassifier\n",
      "2024-11-14 00:47:31,547 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 43980\n",
      "[I 2024-11-14 00:47:31,547] A new study created in memory with name: no-name-e4914564-c9e6-47dd-a1d9-c4af91f118ac\n",
      "[I 2024-11-14 00:47:31,548] A new study created in memory with name: no-name-4a4408bc-b257-4a36-83c3-c997507bd51d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.7654046251238892], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 24, 151375), datetime_complete=datetime.datetime(2024, 11, 14, 0, 47, 27, 845012), params={'n_estimators': 458, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.6052140781935152, 'max_features': 0.32823005879811984, 'min_samples_leaf': 0.19447937531659815}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=1500, log=False, low=20, step=1), 'criterion': CategoricalDistribution(choices=('gini', 'entropy', 'log_loss')), 'bootstrap': CategoricalDistribution(choices=(True,)), 'max_samples': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'max_features': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'min_samples_leaf': FloatDistribution(high=1.0, log=False, low=0.1, step=None)}, trial_id=1, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:47:34,332] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 574, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.24041677639819287, 'max_features': 0.2403950683025824, 'min_samples_leaf': 0.15227525095137953}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:47:34,333] A new study created in memory with name: no-name-c0af464c-f6ca-49cf-a33e-5253faf2cdfb\n",
      "[I 2024-11-14 00:47:36,987] Trial 0 finished with value: 0.7524456519127259 and parameters: {'n_estimators': 458, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.6052140781935152, 'max_features': 0.32823005879811984, 'min_samples_leaf': 0.19447937531659815}. Best is trial 0 with value: 0.7524456519127259.\n",
      "[I 2024-11-14 00:47:36,989] A new study created in memory with name: no-name-4a8f56be-abce-4100-977a-bf7b62fe93e2\n",
      "[I 2024-11-14 00:47:39,420] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 487, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.8813498313568406, 'max_features': 0.6667556660442842, 'min_samples_leaf': 0.41726683712558366}. Best is trial 0 with value: 0.5.\n",
      "2024-11-14 00:47:39,426 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/ExtraTreesClassifier_TPESampler_marginal_43980.csv\n",
      "2024-11-14 00:47:39,427 - __main__ - INFO - Searching hyperparameter space with TPESampler for XGBClassifier\n",
      "2024-11-14 00:47:39,428 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 31\n",
      "[I 2024-11-14 00:47:39,428] A new study created in memory with name: no-name-9e617a78-2c0f-4365-89c0-c54f4598263a\n",
      "[I 2024-11-14 00:47:39,429] A new study created in memory with name: no-name-48d5dd86-1566-4798-acd8-7688cf01d880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.7524456519127259], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 34, 334182), datetime_complete=datetime.datetime(2024, 11, 14, 0, 47, 36, 987678), params={'n_estimators': 458, 'criterion': 'gini', 'bootstrap': True, 'max_samples': 0.6052140781935152, 'max_features': 0.32823005879811984, 'min_samples_leaf': 0.19447937531659815}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=1500, log=False, low=20, step=1), 'criterion': CategoricalDistribution(choices=('gini', 'entropy', 'log_loss')), 'bootstrap': CategoricalDistribution(choices=(True,)), 'max_samples': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'max_features': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'min_samples_leaf': FloatDistribution(high=1.0, log=False, low=0.1, step=None)}, trial_id=1, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:47:42,049] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 1873, 'learning_rate': 0.1804941906677887, 'subsample': 0.7587945476302645, 'booster': 'gbtree', 'max_depth': 9, 'min_child_weight': 20.814367336189438, 'colsample_bytree': 0.16443457513284063, 'colsample_bylevel': 0.06750277604651747, 'reg_alpha': 849.9808989183019, 'reg_lambda': 6.4405075539937195}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:47:42,050] A new study created in memory with name: no-name-aa09a822-9622-47f7-9e8b-37bfcc831457\n",
      "[I 2024-11-14 00:47:43,728] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 1482, 'learning_rate': 0.041907742461594774, 'subsample': 0.4152272727010703, 'booster': 'gbtree', 'max_depth': 12, 'min_child_weight': 72.29131992286271, 'colsample_bytree': 0.2610530646779318, 'colsample_bylevel': 0.11392731284825795, 'reg_alpha': 0.0002935525339557525, 'reg_lambda': 24.341035298636815}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:47:43,731] A new study created in memory with name: no-name-f7efac66-ca92-482b-ad9b-17f6e2b38543\n",
      "[I 2024-11-14 00:47:45,458] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 1579, 'learning_rate': 0.0010672674697233477, 'subsample': 0.34028403750096586, 'booster': 'gbtree', 'max_depth': 2, 'min_child_weight': 111.25714286924307, 'colsample_bytree': 0.6334312326487125, 'colsample_bylevel': 0.35899352083814196, 'reg_alpha': 0.00034697708562294216, 'reg_lambda': 10.251908819044953}. Best is trial 0 with value: 0.5.\n",
      "2024-11-14 00:47:45,465 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/XGBClassifier_TPESampler_marginal_31.csv\n",
      "2024-11-14 00:47:45,467 - __main__ - INFO - Searching hyperparameter space with TPESampler for XGBClassifier\n",
      "2024-11-14 00:47:45,467 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 37\n",
      "[I 2024-11-14 00:47:45,468] A new study created in memory with name: no-name-63375e77-675e-46f3-b501-8ea824f6f017\n",
      "[I 2024-11-14 00:47:45,469] A new study created in memory with name: no-name-b9c4ad33-5b78-4c8f-a87b-4b20147984a3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=0, state=1, values=[0.5], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 39, 429899), datetime_complete=datetime.datetime(2024, 11, 14, 0, 47, 42, 48743), params={'n_estimators': 1873, 'learning_rate': 0.1804941906677887, 'subsample': 0.7587945476302645, 'booster': 'gbtree', 'max_depth': 9, 'min_child_weight': 20.814367336189438, 'colsample_bytree': 0.16443457513284063, 'colsample_bylevel': 0.06750277604651747, 'reg_alpha': 849.9808989183019, 'reg_lambda': 6.4405075539937195}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=5000, log=False, low=1, step=1), 'learning_rate': FloatDistribution(high=0.3, log=True, low=1e-05, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'booster': CategoricalDistribution(choices=('gbtree',)), 'max_depth': IntDistribution(high=15, log=False, low=1, step=1), 'min_child_weight': FloatDistribution(high=128.0, log=False, low=1.0, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'colsample_bylevel': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'reg_alpha': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None)}, trial_id=0, value=None), FrozenTrial(number=1, state=1, values=[0.5], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 42, 51215), datetime_complete=datetime.datetime(2024, 11, 14, 0, 47, 43, 728649), params={'n_estimators': 1482, 'learning_rate': 0.041907742461594774, 'subsample': 0.4152272727010703, 'booster': 'gbtree', 'max_depth': 12, 'min_child_weight': 72.29131992286271, 'colsample_bytree': 0.2610530646779318, 'colsample_bylevel': 0.11392731284825795, 'reg_alpha': 0.0002935525339557525, 'reg_lambda': 24.341035298636815}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=5000, log=False, low=1, step=1), 'learning_rate': FloatDistribution(high=0.3, log=True, low=1e-05, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'booster': CategoricalDistribution(choices=('gbtree',)), 'max_depth': IntDistribution(high=15, log=False, low=1, step=1), 'min_child_weight': FloatDistribution(high=128.0, log=False, low=1.0, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'colsample_bylevel': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'reg_alpha': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None)}, trial_id=1, value=None), FrozenTrial(number=2, state=1, values=[0.5], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 43, 731621), datetime_complete=datetime.datetime(2024, 11, 14, 0, 47, 45, 458273), params={'n_estimators': 1579, 'learning_rate': 0.0010672674697233477, 'subsample': 0.34028403750096586, 'booster': 'gbtree', 'max_depth': 2, 'min_child_weight': 111.25714286924307, 'colsample_bytree': 0.6334312326487125, 'colsample_bylevel': 0.35899352083814196, 'reg_alpha': 0.00034697708562294216, 'reg_lambda': 10.251908819044953}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=5000, log=False, low=1, step=1), 'learning_rate': FloatDistribution(high=0.3, log=True, low=1e-05, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'booster': CategoricalDistribution(choices=('gbtree',)), 'max_depth': IntDistribution(high=15, log=False, low=1, step=1), 'min_child_weight': FloatDistribution(high=128.0, log=False, low=1.0, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'colsample_bylevel': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'reg_alpha': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None)}, trial_id=2, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:47:46,682] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 1873, 'learning_rate': 0.1804941906677887, 'subsample': 0.7587945476302645, 'booster': 'gbtree', 'max_depth': 9, 'min_child_weight': 20.814367336189438, 'colsample_bytree': 0.16443457513284063, 'colsample_bylevel': 0.06750277604651747, 'reg_alpha': 849.9808989183019, 'reg_lambda': 6.4405075539937195}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:47:46,684] A new study created in memory with name: no-name-b8ef0a34-b77a-4074-927a-44444640369b\n",
      "[I 2024-11-14 00:47:47,751] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 1482, 'learning_rate': 0.041907742461594774, 'subsample': 0.4152272727010703, 'booster': 'gbtree', 'max_depth': 12, 'min_child_weight': 72.29131992286271, 'colsample_bytree': 0.2610530646779318, 'colsample_bylevel': 0.11392731284825795, 'reg_alpha': 0.0002935525339557525, 'reg_lambda': 24.341035298636815}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:47:47,752] A new study created in memory with name: no-name-c0b4455c-ab0c-42f1-a9e7-3304b9df505a\n",
      "[I 2024-11-14 00:47:48,750] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 1579, 'learning_rate': 0.0010672674697233477, 'subsample': 0.34028403750096586, 'booster': 'gbtree', 'max_depth': 2, 'min_child_weight': 111.25714286924307, 'colsample_bytree': 0.6334312326487125, 'colsample_bylevel': 0.35899352083814196, 'reg_alpha': 0.00034697708562294216, 'reg_lambda': 10.251908819044953}. Best is trial 0 with value: 0.5.\n",
      "2024-11-14 00:47:48,757 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/XGBClassifier_TPESampler_marginal_37.csv\n",
      "2024-11-14 00:47:48,759 - __main__ - INFO - Searching hyperparameter space with TPESampler for XGBClassifier\n",
      "2024-11-14 00:47:48,759 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 45062\n",
      "[I 2024-11-14 00:47:48,760] A new study created in memory with name: no-name-24d53a6d-11e0-4a3d-b9b4-57cab6c216e5\n",
      "[I 2024-11-14 00:47:48,761] A new study created in memory with name: no-name-e32380ee-1544-4d98-89c0-90fb257f4393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=0, state=1, values=[0.5], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 45, 469481), datetime_complete=datetime.datetime(2024, 11, 14, 0, 47, 46, 682323), params={'n_estimators': 1873, 'learning_rate': 0.1804941906677887, 'subsample': 0.7587945476302645, 'booster': 'gbtree', 'max_depth': 9, 'min_child_weight': 20.814367336189438, 'colsample_bytree': 0.16443457513284063, 'colsample_bylevel': 0.06750277604651747, 'reg_alpha': 849.9808989183019, 'reg_lambda': 6.4405075539937195}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=5000, log=False, low=1, step=1), 'learning_rate': FloatDistribution(high=0.3, log=True, low=1e-05, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'booster': CategoricalDistribution(choices=('gbtree',)), 'max_depth': IntDistribution(high=15, log=False, low=1, step=1), 'min_child_weight': FloatDistribution(high=128.0, log=False, low=1.0, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'colsample_bylevel': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'reg_alpha': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None)}, trial_id=0, value=None), FrozenTrial(number=1, state=1, values=[0.5], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 46, 685082), datetime_complete=datetime.datetime(2024, 11, 14, 0, 47, 47, 750905), params={'n_estimators': 1482, 'learning_rate': 0.041907742461594774, 'subsample': 0.4152272727010703, 'booster': 'gbtree', 'max_depth': 12, 'min_child_weight': 72.29131992286271, 'colsample_bytree': 0.2610530646779318, 'colsample_bylevel': 0.11392731284825795, 'reg_alpha': 0.0002935525339557525, 'reg_lambda': 24.341035298636815}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=5000, log=False, low=1, step=1), 'learning_rate': FloatDistribution(high=0.3, log=True, low=1e-05, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'booster': CategoricalDistribution(choices=('gbtree',)), 'max_depth': IntDistribution(high=15, log=False, low=1, step=1), 'min_child_weight': FloatDistribution(high=128.0, log=False, low=1.0, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'colsample_bylevel': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'reg_alpha': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None)}, trial_id=1, value=None), FrozenTrial(number=2, state=1, values=[0.5], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 47, 753188), datetime_complete=datetime.datetime(2024, 11, 14, 0, 47, 48, 750406), params={'n_estimators': 1579, 'learning_rate': 0.0010672674697233477, 'subsample': 0.34028403750096586, 'booster': 'gbtree', 'max_depth': 2, 'min_child_weight': 111.25714286924307, 'colsample_bytree': 0.6334312326487125, 'colsample_bylevel': 0.35899352083814196, 'reg_alpha': 0.00034697708562294216, 'reg_lambda': 10.251908819044953}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=5000, log=False, low=1, step=1), 'learning_rate': FloatDistribution(high=0.3, log=True, low=1e-05, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'booster': CategoricalDistribution(choices=('gbtree',)), 'max_depth': IntDistribution(high=15, log=False, low=1, step=1), 'min_child_weight': FloatDistribution(high=128.0, log=False, low=1.0, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'colsample_bylevel': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'reg_alpha': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None)}, trial_id=2, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:47:51,128] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 1873, 'learning_rate': 0.1804941906677887, 'subsample': 0.7587945476302645, 'booster': 'gbtree', 'max_depth': 9, 'min_child_weight': 20.814367336189438, 'colsample_bytree': 0.16443457513284063, 'colsample_bylevel': 0.06750277604651747, 'reg_alpha': 849.9808989183019, 'reg_lambda': 6.4405075539937195}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:47:51,130] A new study created in memory with name: no-name-47da54a2-0d9d-42b5-aa9d-634ac2c0eb3a\n",
      "[I 2024-11-14 00:47:53,571] Trial 0 finished with value: 0.8346409048028358 and parameters: {'n_estimators': 1482, 'learning_rate': 0.041907742461594774, 'subsample': 0.4152272727010703, 'booster': 'gbtree', 'max_depth': 12, 'min_child_weight': 72.29131992286271, 'colsample_bytree': 0.2610530646779318, 'colsample_bylevel': 0.11392731284825795, 'reg_alpha': 0.0002935525339557525, 'reg_lambda': 24.341035298636815}. Best is trial 0 with value: 0.8346409048028358.\n",
      "[I 2024-11-14 00:47:53,573] A new study created in memory with name: no-name-a0ead366-45c3-49c0-bbd9-5a9e1aa65dd7\n",
      "[I 2024-11-14 00:47:56,906] Trial 0 finished with value: 0.8255162981511417 and parameters: {'n_estimators': 1579, 'learning_rate': 0.0010672674697233477, 'subsample': 0.34028403750096586, 'booster': 'gbtree', 'max_depth': 2, 'min_child_weight': 111.25714286924307, 'colsample_bytree': 0.6334312326487125, 'colsample_bylevel': 0.35899352083814196, 'reg_alpha': 0.00034697708562294216, 'reg_lambda': 10.251908819044953}. Best is trial 0 with value: 0.8255162981511417.\n",
      "2024-11-14 00:47:56,913 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/XGBClassifier_TPESampler_marginal_45062.csv\n",
      "2024-11-14 00:47:56,914 - __main__ - INFO - Searching hyperparameter space with TPESampler for XGBClassifier\n",
      "2024-11-14 00:47:56,914 - __main__ - INFO - Optimizing hyperparameters for dataset separately, dataset 43980\n",
      "[I 2024-11-14 00:47:56,915] A new study created in memory with name: no-name-49474720-343a-4719-9c55-212aa6749bc8\n",
      "[I 2024-11-14 00:47:56,916] A new study created in memory with name: no-name-3ebff579-a80c-4449-abf0-ee485af27632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.8346409048028358], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 51, 130896), datetime_complete=datetime.datetime(2024, 11, 14, 0, 47, 53, 571451), params={'n_estimators': 1482, 'learning_rate': 0.041907742461594774, 'subsample': 0.4152272727010703, 'booster': 'gbtree', 'max_depth': 12, 'min_child_weight': 72.29131992286271, 'colsample_bytree': 0.2610530646779318, 'colsample_bylevel': 0.11392731284825795, 'reg_alpha': 0.0002935525339557525, 'reg_lambda': 24.341035298636815}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=5000, log=False, low=1, step=1), 'learning_rate': FloatDistribution(high=0.3, log=True, low=1e-05, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'booster': CategoricalDistribution(choices=('gbtree',)), 'max_depth': IntDistribution(high=15, log=False, low=1, step=1), 'min_child_weight': FloatDistribution(high=128.0, log=False, low=1.0, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'colsample_bylevel': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'reg_alpha': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None)}, trial_id=1, value=None)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-14 00:47:58,643] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 1873, 'learning_rate': 0.1804941906677887, 'subsample': 0.7587945476302645, 'booster': 'gbtree', 'max_depth': 9, 'min_child_weight': 20.814367336189438, 'colsample_bytree': 0.16443457513284063, 'colsample_bylevel': 0.06750277604651747, 'reg_alpha': 849.9808989183019, 'reg_lambda': 6.4405075539937195}. Best is trial 0 with value: 0.5.\n",
      "[I 2024-11-14 00:47:58,645] A new study created in memory with name: no-name-48b30d8a-9f12-4ac0-801c-7484e3b9c05a\n",
      "[I 2024-11-14 00:48:00,681] Trial 0 finished with value: 0.8006660599288736 and parameters: {'n_estimators': 1482, 'learning_rate': 0.041907742461594774, 'subsample': 0.4152272727010703, 'booster': 'gbtree', 'max_depth': 12, 'min_child_weight': 72.29131992286271, 'colsample_bytree': 0.2610530646779318, 'colsample_bylevel': 0.11392731284825795, 'reg_alpha': 0.0002935525339557525, 'reg_lambda': 24.341035298636815}. Best is trial 0 with value: 0.8006660599288736.\n",
      "[I 2024-11-14 00:48:00,683] A new study created in memory with name: no-name-8171a6de-b348-475d-b88a-e60f5a85a7ce\n",
      "[I 2024-11-14 00:48:02,114] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 1579, 'learning_rate': 0.0010672674697233477, 'subsample': 0.34028403750096586, 'booster': 'gbtree', 'max_depth': 2, 'min_child_weight': 111.25714286924307, 'colsample_bytree': 0.6334312326487125, 'colsample_bylevel': 0.35899352083814196, 'reg_alpha': 0.00034697708562294216, 'reg_lambda': 10.251908819044953}. Best is trial 0 with value: 0.5.\n",
      "2024-11-14 00:48:02,122 - __main__ - INFO - Results saved to /home/igor/Repos/AutoML/results/XGBClassifier_TPESampler_marginal_43980.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FrozenTrial(number=1, state=1, values=[0.8006660599288736], datetime_start=datetime.datetime(2024, 11, 14, 0, 47, 58, 645715), datetime_complete=datetime.datetime(2024, 11, 14, 0, 48, 0, 680998), params={'n_estimators': 1482, 'learning_rate': 0.041907742461594774, 'subsample': 0.4152272727010703, 'booster': 'gbtree', 'max_depth': 12, 'min_child_weight': 72.29131992286271, 'colsample_bytree': 0.2610530646779318, 'colsample_bylevel': 0.11392731284825795, 'reg_alpha': 0.0002935525339557525, 'reg_lambda': 24.341035298636815}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=5000, log=False, low=1, step=1), 'learning_rate': FloatDistribution(high=0.3, log=True, low=1e-05, step=None), 'subsample': FloatDistribution(high=1.0, log=False, low=0.1, step=None), 'booster': CategoricalDistribution(choices=('gbtree',)), 'max_depth': IntDistribution(high=15, log=False, low=1, step=1), 'min_child_weight': FloatDistribution(high=128.0, log=False, low=1.0, step=None), 'colsample_bytree': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'colsample_bylevel': FloatDistribution(high=1.0, log=False, low=0.01, step=None), 'reg_alpha': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None), 'reg_lambda': FloatDistribution(high=10000.0, log=True, low=0.0001, step=None)}, trial_id=1, value=None)]\n",
      "Best params for lr:\n",
      "  Dataset 31:\n",
      "    C: 0.03350945131274967\n",
      "    penalty: elasticnet\n",
      "    l1_ratio: 0.00648817727333381\n",
      "    class_weight: balanced\n",
      "    max_iter: 1500\n",
      "    solver: saga\n",
      "  Dataset 37:\n",
      "    C: 0.09915644566638401\n",
      "    penalty: elasticnet\n",
      "    l1_ratio: 0.6351221010640696\n",
      "    class_weight: balanced\n",
      "    max_iter: 1500\n",
      "    solver: saga\n",
      "  Dataset 45062:\n",
      "    C: 0.09915644566638401\n",
      "    penalty: elasticnet\n",
      "    l1_ratio: 0.6351221010640696\n",
      "    class_weight: balanced\n",
      "    max_iter: 1500\n",
      "    solver: saga\n",
      "  Dataset 43980:\n",
      "    C: 0.03350945131274967\n",
      "    penalty: elasticnet\n",
      "    l1_ratio: 0.00648817727333381\n",
      "    class_weight: balanced\n",
      "    max_iter: 1500\n",
      "    solver: saga\n",
      "\n",
      "\n",
      "Best params for et:\n",
      "  Dataset 31:\n",
      "    n_estimators: 458\n",
      "    criterion: gini\n",
      "    bootstrap: True\n",
      "    max_samples: 0.6052140781935152\n",
      "    max_features: 0.32823005879811984\n",
      "    min_samples_leaf: 0.19447937531659815\n",
      "  Dataset 37:\n",
      "    n_estimators: 458\n",
      "    criterion: gini\n",
      "    bootstrap: True\n",
      "    max_samples: 0.6052140781935152\n",
      "    max_features: 0.32823005879811984\n",
      "    min_samples_leaf: 0.19447937531659815\n",
      "  Dataset 45062:\n",
      "    n_estimators: 458\n",
      "    criterion: gini\n",
      "    bootstrap: True\n",
      "    max_samples: 0.6052140781935152\n",
      "    max_features: 0.32823005879811984\n",
      "    min_samples_leaf: 0.19447937531659815\n",
      "  Dataset 43980:\n",
      "    n_estimators: 458\n",
      "    criterion: gini\n",
      "    bootstrap: True\n",
      "    max_samples: 0.6052140781935152\n",
      "    max_features: 0.32823005879811984\n",
      "    min_samples_leaf: 0.19447937531659815\n",
      "\n",
      "\n",
      "Best params for xgb:\n",
      "  Dataset 31:\n",
      "    n_estimators: 1873\n",
      "    learning_rate: 0.1804941906677887\n",
      "    subsample: 0.7587945476302645\n",
      "    booster: gbtree\n",
      "    max_depth: 9\n",
      "    min_child_weight: 20.814367336189438\n",
      "    colsample_bytree: 0.16443457513284063\n",
      "    colsample_bylevel: 0.06750277604651747\n",
      "    reg_alpha: 849.9808989183019\n",
      "    reg_lambda: 6.4405075539937195\n",
      "  Dataset 37:\n",
      "    n_estimators: 1873\n",
      "    learning_rate: 0.1804941906677887\n",
      "    subsample: 0.7587945476302645\n",
      "    booster: gbtree\n",
      "    max_depth: 9\n",
      "    min_child_weight: 20.814367336189438\n",
      "    colsample_bytree: 0.16443457513284063\n",
      "    colsample_bylevel: 0.06750277604651747\n",
      "    reg_alpha: 849.9808989183019\n",
      "    reg_lambda: 6.4405075539937195\n",
      "  Dataset 45062:\n",
      "    n_estimators: 1482\n",
      "    learning_rate: 0.041907742461594774\n",
      "    subsample: 0.4152272727010703\n",
      "    booster: gbtree\n",
      "    max_depth: 12\n",
      "    min_child_weight: 72.29131992286271\n",
      "    colsample_bytree: 0.2610530646779318\n",
      "    colsample_bylevel: 0.11392731284825795\n",
      "    reg_alpha: 0.0002935525339557525\n",
      "    reg_lambda: 24.341035298636815\n",
      "  Dataset 43980:\n",
      "    n_estimators: 1482\n",
      "    learning_rate: 0.041907742461594774\n",
      "    subsample: 0.4152272727010703\n",
      "    booster: gbtree\n",
      "    max_depth: 12\n",
      "    min_child_weight: 72.29131992286271\n",
      "    colsample_bytree: 0.2610530646779318\n",
      "    colsample_bylevel: 0.11392731284825795\n",
      "    reg_alpha: 0.0002935525339557525\n",
      "    reg_lambda: 24.341035298636815\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampler = SAMPLERS[1]\n",
    "best_params_dict = {}\n",
    "\n",
    "for model, param_grid in MODELS:\n",
    "    for ID, X, y in zip(DATASET_IDS, Xs, ys):\n",
    "        trials, study = run_experiment_marginal(model, sampler, X, y, ID, param_grid, results_dir, n_trials=150)\n",
    "        model_name = {'LogisticRegression': 'lr', 'ExtraTreesClassifier': 'et', 'XGBClassifier': 'xgb'}[model.__name__]\n",
    "        save_study_to_pickle_marginal(study, model_name, 'BS', ID)\n",
    "        best_params = study.best_trials[0].params\n",
    "    \n",
    "        if model_name not in best_params_dict:\n",
    "            best_params_dict[model_name] = {}\n",
    "        best_params_dict[model_name][ID] = best_params\n",
    "        \n",
    "with open(os.path.join(results_bestparams_dir, 'best_params_dict_TPE.json'), 'w') as f:\n",
    "    json.dump(best_params_dict, f)\n",
    "    \n",
    "for model_name, datasets in best_params_dict.items():\n",
    "    print(f\"Best params for {model_name}:\")\n",
    "    for ID, params in datasets.items():\n",
    "        print(f\"  Dataset {ID}:\")\n",
    "        for param_name, value in params.items():\n",
    "            print(f\"    {param_name}: {value}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
